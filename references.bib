

@inproceedings{tibshirani2020conformal,
  title     = {Conformal Prediction Under Covariate Shift},
  author    = {Ryan J. Tibshirani and Rina Foygel Barber and Emmanuel J. Cand\`es and Aaditya Ramdas},
  year      = {2019},
  booktitle = {Advances in Neural Information Processing Systems}
}


@inproceedings{romano2019conformalized,
  title     = {Conformalized quantile regression},
  author    = {Romano, Yaniv and Patterson, Evan and Cand\`es, Emmanuel J.},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {32},
  pages     = {3543--3553},
  year      = {2019}
}

@article{ravi2016deep,
  title     = {Deep learning for health informatics},
  author    = {Rav{\`\i}, Daniele and Wong, Charence and Deligianni, Fani and Berthelot, Melissa and Andreu-Perez, Javier and Lo, Benny and Yang, Guang-Zhong},
  journal   = {IEEE journal of biomedical and health informatics},
  volume    = {21},
  number    = {1},
  pages     = {4--21},
  year      = {2016},
  publisher = {IEEE}
}

@article{zhou2021deepvit,
  title   = {Deepvit: Towards deeper vision transformer},
  author  = {Zhou, Daquan and Kang, Bingyi and Jin, Xiaojie and Yang, Linjie and Lian, Xiaochen and Jiang, Zihang and Hou, Qibin and Feng, Jiashi},
  journal = {arXiv preprint arXiv:2103.11886},
  year    = {2021}
}

@inproceedings{szegedy2017inception,
  title     = {Inception-v4, inception-resnet and the impact of residual connections on learning},
  author    = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
  booktitle = {Thirty-first AAAI conference on artificial intelligence},
  year      = {2017}
}


@article{chandak2021universal,
  title   = {Universal Off-Policy Evaluation},
  author  = {Chandak, Yash and Niekum, Scott and da Silva, Bruno Castro and Learned-Miller, Erik and Brunskill, Emma and Thomas, Philip S},
  journal = {arXiv preprint arXiv:2104.12820},
  year    = {2021}
}

@inproceedings{keramati2020being,
  title     = {Being optimistic to be conservative: Quickly learning a cvar policy},
  author    = {Keramati, Ramtin and Dann, Christoph and Tamkin, Alex and Brunskill, Emma},
  booktitle = {AAAI Conference on Artificial Intelligence},
  volume    = {34},
  pages     = {4436--4443},
  year      = {2020}
}

@inproceedings{parmar2018image,
  title        = {Image transformer},
  author       = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  booktitle    = {International Conference on Machine Learning},
  pages        = {4055--4064},
  year         = {2018},
  organization = {PMLR}
}

@article{beltagy2020longformer,
  title   = {Longformer: The long-document transformer},
  author  = {Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal = {arXiv preprint arXiv:2004.05150},
  year    = {2020}
}

@article{purushotham2017benchmark,
  title   = {Benchmark of deep learning models on large healthcare mimic datasets},
  author  = {Purushotham, Sanjay and Meng, Chuizheng and Che, Zhengping and Liu, Yan},
  journal = {arXiv preprint arXiv:1710.08531},
  year    = {2017}
}

@book{vovk2005algorithmic,
  title     = {Algorithmic Learning in a Random World},
  author    = {Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
  year      = {2005},
  publisher = {Springer Science \& Business Media}
}

@article{lei2014distribution,
  title     = {Distribution-free prediction bands for non-parametric regression},
  author    = {Lei, Jing and Wasserman, Larry},
  journal   = {Journal of the Royal Statistical Society: Series \textup{B}},
  pages     = {71--96},
  year      = {2014},
  publisher = {JSTOR}
}

@article{foygel2021limits,
  title     = {The limits of distribution-free conditional predictive inference},
  author    = {Foygel Barber, Rina and Cand\`es, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal   = {Information and Inference: A Journal of the IMA},
  volume    = {10},
  number    = {2},
  pages     = {455--482},
  year      = {2021},
  publisher = {Oxford University Press}
}

@article{shafer2008tutorial,
  title   = {A Tutorial on Conformal Prediction.},
  author  = {Shafer, Glenn and Vovk, Vladimir},
  journal = {Journal of Machine Learning Research},
  volume  = {9},
  number  = {3},
  year    = {2008}
}

@article{osama2020learning,
  title   = {Learning Robust Decision Policies from Observational Data},
  author  = {Osama, Muhammad and Zachariah, Dave and Stoica, Peter},
  journal = {arXiv preprint arXiv:2006.02355},
  year    = {2020}
}


@article{lei2020conformal,
  title   = {Conformal inference of counterfactuals and individual treatment effects},
  author  = {Lei, Lihua and Cand{\`e}s, Emmanuel J},
  journal = {Journal of the Royal Statistical Society: Series \textup{B}},
  pages   = {911--938},
  year    = {2021}
}

@article{uncertainty1,
  author  = {L{{\'e}}on Bottou and Jonas Peters and Joaquin Qui{{\~n}}onero-Candela and Denis X. Charles and D. Max Chickering and Elon Portugaly and Dipankar Ray and Patrice Simard and Ed Snelson},
  title   = {Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising},
  journal = {Journal of Machine Learning Research},
  year    = {2013},
  volume  = {14},
  number  = {65},
  pages   = {3207-3260},
  url     = {http://jmlr.org/papers/v14/bottou13a.html}
}
@inproceedings{uncertainty2,
  author    = {Philip S. Thomas and Georgios Theocharous and Mohammad Ghavamzadeh},
  title     = {High-Confidence Off-Policy Evaluation},
  year      = {2015},
  booktitle = {AAAI Conference on Artificial Intelligence}
}

@article{uncertainty3,
  author  = {Adith Swaminathan and Thorsten Joachims},
  title   = {Batch Learning from Logged Bandit Feedback through Counterfactual Risk Minimization},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {52},
  pages   = {1731-1755}
}

@inproceedings{uncertainty4,
  author    = {Swaminathan, Adith and Joachims, Thorsten},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {The Self-Normalized Estimator for Counterfactual Learning},
  volume    = {28},
  year      = {2015}
}

@inproceedings{uncertainty5,
  title     = {Confident off-policy evaluation and selection through self-normalized importance weighting},
  author    = {Kuzborskij, Ilja and Vernade, Claire and Gy{\"{o}}rgy, Andr{\'{a}}s and Szepesv{\'a}ri, Csaba},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  pages     = {640--648},
  year      = {2021}
}


@article{concentrationineq,
  title     = {Concentration Inequalities for Statistical Inference},
  volume    = {37},
  issn      = {2707-8523},
  url       = {http://dx.doi.org/10.4208/cmr.2020-0041},
  doi       = {10.4208/cmr.2020-0041},
  number    = {1},
  journal   = {Communications in Mathematical Research},
  publisher = {Global Science Press},
  author    = {Chen, Huiming Zhang & Song Xi},
  year      = {2021},
  month     = {Jun},
  pages     = {1–85}
}

@article{risk-assessment,
  author  = {Audrey Huang and
             Liu Leqi and
             Zachary C. Lipton and
             Kamyar Azizzadenesheli},
  title   = {Off-Policy Risk Assessment in Contextual Bandits},
  journal = {arXiv preprint arXiv:2104.08977},
  year    = {2021}
}

@inproceedings{distributional-rl,
  title     = {A distributional perspective on reinforcement learning},
  author    = {Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle = {International Conference on Machine Learning},
  pages     = {449--458},
  year      = {2017}
}

@article{yin2021conformal,
  title   = {Conformal Sensitivity Analysis for Individual Treatment Effects},
  author  = {Yin, Mingzhang and Shi, Claudia and Wang, Yixin and Blei, David M},
  journal = {arXiv preprint arXiv:2112.03493},
  year    = {2021}
}


@article{bietti2018contextual,
  title   = {A contextual bandit bake-off},
  author  = {Bietti, Alberto and Agarwal, Alekh and Langford, John},
  journal = {arXiv preprint arXiv:1802.04064},
  year    = {2018}
}

@article{jin2021sensitivity,
  title   = {Sensitivity Analysis of Individual Treatment Effects: A Robust Conformal Inference Approach},
  author  = {Jin, Ying and Ren, Zhimei and Cand{\`e}s, Emmanuel J},
  journal = {arXiv preprint arXiv:2111.12161},
  year    = {2021}
}

@inproceedings{swaminathan2016off,
  title     = {Off-policy evaluation for slate recommendation},
  author    = {Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017}
}

@article{msr,
  author  = {Tao Qin and
             Tie{-}Yan Liu},
  title   = {Introducing {LETOR} 4.0 Datasets},
  journal = {arXiv preprint arXiv:1306.2597},
  year    = {2013}
}

@article{conf-bates,
  author  = {Anastasios N. Angelopoulos and
             Stephen Bates},
  title   = {A Gentle Introduction to Conformal Prediction and Distribution-Free
             Uncertainty Quantification},
  journal = {arXiv preprint arXiv:2107.07511},
  year    = {2021}
}

@article{Rosenthal1970OnTS,
  title   = {On the subspaces of $\textup{L}_p~(p>2)$ spanned by sequences of independent random variables},
  author  = {Haskell P. Rosenthal},
  journal = {Israel Journal of Mathematics},
  year    = {1970},
  volume  = {8},
  pages   = {273-303}
}

@article{kuroki2014measurement,
  author   = {Kuroki, Manabu and Pearl, Judea},
  title    = {{Measurement bias and effect restoration in causal inference}},
  journal  = {Biometrika},
  volume   = {101},
  number   = {2},
  pages    = {423-437},
  year     = {2014},
  month    = {03},
  abstract = {{This paper highlights several areas where graphical techniques can be harnessed to address the problem of measurement errors in causal inference. In particular, it discusses the control of unmeasured confounders in parametric and nonparametric models and the computational problem of obtaining bias-free effect estimates in such models. We derive new conditions under which causal effects can be restored by observing proxy variables of unmeasured confounders with/without external studies.}},
  issn     = {0006-3444},
  doi      = {10.1093/biomet/ast066},
  url      = {https://doi.org/10.1093/biomet/ast066},
  eprint   = {https://academic.oup.com/biomet/article-pdf/101/2/423/5027388/ast066.pdf}
}





@misc{xu2024kernel,
  title         = {Kernel Single Proxy Control for Deterministic Confounding},
  author        = {Liyuan Xu and Arthur Gretton},
  year          = {2024},
  eprint        = {2308.04585},
  archiveprefix = {arXiv},
  primaryclass  = {id='stat.ML' full_name='Machine Learning' is_active=True alt_name=None in_archive='stat' is_general=False description='Covers machine learning papers (supervised, unsupervised, semi-supervised learning, graphical models, reinforcement learning, bandits, high dimensional inference, etc.) with a statistical or theoretical grounding'}
}

@article{limits-conf,
  author   = {Foygel Barber, Rina and Candès, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  title    = {{The limits of distribution-free conditional predictive inference}},
  journal  = {Information and Inference},
  volume   = {10},
  number   = {2},
  pages    = {455-482},
  year     = {2020},
  month    = {08},
  abstract = {{We consider the problem of distribution-free predictive inference, with the goal of producing predictive coverage guarantees that hold conditionally rather than marginally. Existing methods such as conformal prediction offer marginal coverage guarantees, where predictive coverage holds on average over all possible test points, but this is not sufficient for many practical applications where we would like to know that our predictions are valid for a given individual, not merely on average over a population. On the other hand, exact conditional inference guarantees are known to be impossible without imposing assumptions on the underlying distribution. In this work, we aim to explore the space in between these two and examine what types of relaxations of the conditional coverage property would alleviate some of the practical concerns with marginal coverage guarantees while still being possible to achieve in a distribution-free setting.}},
  issn     = {2049-8772},
  doi      = {10.1093/imaiai/iaaa017},
  url      = {https://doi.org/10.1093/imaiai/iaaa017},
  eprint   = {https://academic.oup.com/imaiai/article-pdf/10/2/455/38549621/iaaa017.pdf}
}
@article{Romano2020With,
  journal = {Harvard Data Science Review},
  number  = {2},
  title   = {With Malice Toward None: Assessing Uncertainty via Equalized Coverage},
  volume  = {2},
  author  = {Romano, Yaniv and Barber, Rina Foygel and Sabatti, Chiara and Candès, Emmanuel J.},
  date    = {2020-04-30},
  year    = {2020},
  month   = {4},
  day     = {30}
}


@article{stutz2021learning,
  title   = {Learning Optimal Conformal Classifiers},
  author  = {Stutz, David and Dvijotham, Krishnamurthy and Cemgil, Ali Taylan and Doucet, Arnaud},
  journal = {International Conference on Representation Learning},
  year    = {2022}
}



@article{joseph2016fairness,
  title   = {Fairness in learning: Classic and contextual bandits},
  author  = {Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Roth, Aaron},
  journal = {arXiv preprint arXiv:1605.07139},
  year    = {2016}
}

@article{altschuler2019best,
  title   = {Best Arm Identification for Contaminated Bandits.},
  author  = {Altschuler, Jason and Brunel, Victor-Emmanuel and Malek, Alan},
  journal = {Journal of Machine Learning Research},
  volume  = {20},
  number  = {91},
  pages   = {1--39},
  year    = {2019}
}


@article{kassraie2021neural,
  title   = {Neural Contextual Bandits without Regret},
  author  = {Kassraie, Parnian and Krause, Andreas},
  journal = {arXiv preprint arXiv:2107.03144},
  year    = {2021}
}

@article{doubly-robust,
  title     = {Doubly Robust Policy Evaluation and Optimization},
  volume    = {29},
  number    = {4},
  journal   = {Statistical Science},
  publisher = {Institute of Mathematical Statistics},
  author    = {Dudík, Miroslav and Erhan, Dumitru and Langford, John and Li, Lihong},
  year      = {2014}
}
@inproceedings{adaptive-ope,
  author    = {Wang, Yu-Xiang and Agarwal, Alekh and Dud\'{\i}k, Miroslav},
  title     = {Optimal and Adaptive Off-Policy Evaluation in Contextual Bandits},
  year      = {2017},
  booktitle = {International Conference on Machine Learning},
  pages     = {3589–3597}
}
@article{rubin,
  author  = {Donald B. Rubin},
  title   = {Estimating causal effects of treatments in randomized and nonrandomized studies},
  journal = {Journal of Educational Psychology},
  volume  = {66},
  pages   = {688–701},
  year    = {1974}
}
@article{rubin_po,
  issn    = {01621459},
  title   = {Causal Inference Using Potential Outcomes: Design, Modeling, Decisions},
  author  = {Donald B. Rubin},
  journal = {Journal of the American Statistical Association},
  number  = {469},
  pages   = {322--331},
  volume  = {100},
  year    = {2005}
}
@article{neyman,
  author    = {Jerzy Splawa-Neyman},
  title     = {On the application of Probability Theory to Agricultural Experiments. {E}ssay on Principles. {S}ection 9},
  volume    = {5},
  journal   = {Statistical Science},
  number    = {4},
  publisher = {Institute of Mathematical Statistics},
  pages     = {465 -- 472},
  year      = {1990}
}


@inproceedings{vovk2012,
  title     = {Conditional Validity of Inductive Conformal Predictors},
  author    = {Vovk, Vladimir},
  booktitle = {Proceedings of the Asian Conference on Machine Learning},
  pages     = {475--490},
  year      = {2012},
  editor    = {Hoi, Steven C. H. and Buntine, Wray},
  volume    = {25},
  series    = {Proceedings of Machine Learning Research},
  address   = {Singapore Management University, Singapore},
  month     = {04--06 Nov},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v25/vovk12/vovk12.pdf},
  url       = {https://proceedings.mlr.press/v25/vovk12.html},
  abstract  = {Conformal predictors are set predictors that are automatically valid in the sense of having coverage probability equal to or exceeding a given confidence level. Inductive conformal predictors are a computationally efficient version of conformal predictors satisfying the same property of validity. However, inductive conformal predictors have been only known to control unconditional coverage probability. This paper explores various versions of conditional validity and various ways to achieve them using inductive conformal predictors and their modifications.}
}



@article{drobust,
  author     = {Yi Su and
                Maria Dimakopoulou and
                Akshay Krishnamurthy and
                Miroslav Dud{\'{\i}}k},
  title      = {Doubly robust off-policy evaluation with shrinkage},
  journal    = {CoRR},
  volume     = {abs/1907.09623},
  year       = {2019},
  url        = {http://arxiv.org/abs/1907.09623},
  eprinttype = {arXiv},
  eprint     = {1907.09623},
  timestamp  = {Tue, 30 Jul 2019 12:52:26 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1907-09623.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ope-rl,
  author    = {Xie, Tengyang and Ma, Yifei and Wang, Yu-Xiang},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling},
  url       = {https://proceedings.neurips.cc/paper/2019/file/4ffb0d2ba92f664c2281970110a2e071-Paper.pdf},
  volume    = {32},
  year      = {2019}
}


@inproceedings{sontag,
  title     = {Counterfactual Off-Policy Evaluation with {G}umbel-Max Structural Causal Models},
  author    = {Oberst, Michael and Sontag, David},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {4881--4890},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/oberst19a/oberst19a.pdf},
  url       = {https://proceedings.mlr.press/v97/oberst19a.html},
  abstract  = {We introduce an off-policy evaluation procedure for highlighting episodes where applying a reinforcement learned (RL) policy is likely to have produced a substantially different outcome than the observed policy. In particular, we introduce a class of structural causal models (SCMs) for generating counterfactual trajectories in finite partially observable Markov Decision Processes (POMDPs). We see this as a useful procedure for off-policy “debugging” in high-risk settings (e.g., healthcare); by decomposing the expected difference in reward between the RL and observed policy into specific episodes, we can identify episodes where the counterfactual difference in reward is most dramatic. This in turn can be used to facilitate review of specific episodes by domain experts. We demonstrate the utility of this procedure with a synthetic environment of sepsis management.}
}

@inproceedings{structuredinf,
  title     = {Structured inference networks for nonlinear state space models},
  author    = {Krishnan, Rahul and Shalit, Uri and Sontag, David},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {31},
  number    = {1},
  year      = {2017}
}

@article{econometrics,
  title     = {Indirect inference},
  author    = {Gourieroux, Christian and Monfort, Alain and Renault, Eric},
  journal   = {Journal of applied econometrics},
  volume    = {8},
  number    = {S1},
  pages     = {S85--S118},
  year      = {1993},
  publisher = {Wiley Online Library}
}

@article{evo-bio,
  author  = {Mark A Beaumont and Wenyang Zhang and David J Balding},
  title   = {Approximate bayesian computation in population
             genetics},
  journal = {Genetics},
  volume  = {4},
  number  = {162},
  pages   = {2025–2035},
  year    = {2002}
}
@article{cosmology,
  author    = {Chad M Schafer and Peter E Freeman},
  title     = {Likelihood-free inference in cosmology: Potential for the estimation of luminosity functions.},
  journal   = {Statistical Challenges in Modern Astronomy},
  volume    = {V},
  pages     = { 3–19},
  publisher = {Springer},
  year      = {2012}
}
@article{sim2real,
  author  = {Xue Bin Peng and Marcin Andrychowicz and Wojciech Zaremba and Pieter Abbeel},
  title   = {Sim-to-real transfer of robotic control with dynamics randomization.},
  journal = {IEEE International Conference on Robotics and Automation (ICRA)},
  pages   = {1-8},
  year    = {2018}
}


@article{pulse,
  abstract      = {The Pulse Physiology Platform is an open-source software application designed to enable accurate and consistent, real-time physiologic simulations for improved medical training and clinical decision-making tools. The platform includes a physiology engine comprised of well-validated lumped-parameter models, differential equations representing feedback mechanisms, and a pharmacokinetic/pharmacodynamic model. The platform also includes a common data model for standard model and data definitions and a common software interface for engine control and robust physics-based circuit and transport solvers. The Pulse Platform has been incorporated into a number of commercial, research, and academic tools for medical simulation. Significance: The Pulse Platform is an innovative, well-validated, open-source tool for medical modeling and simulation in the training and clinical decision-making field.},
  author        = {Bray, Aaron and Webb, Jeffrey B. and Enquobahrie, Andinet and Vicory, Jared and Heneghan, Jerry and Hubal, Robert and TerMaath, Stephanie and Asare, Philip and Clipp, Rachel B.},
  da            = {2019/05/01},
  date-added    = {2022-12-02 19:12:08 +0000},
  date-modified = {2 022-12-02 19:12:08 +0000},
  doi           = {10.1007/s42399-019-00053-w},
  id            = {Bray2019},
  isbn          = {2523-8973},
  journal       = {SN Comprehensive Clinical Medicine},
  number        = {5},
  pages         = {362--377},
  title         = {{Pulse Physiology Engine: an Open-Source Software Platform for Computational Modeling of Human Medical Simulation}},
  ty            = {JOUR},
  url           = {https://doi.org/10.1007/s42399-019-00053-w},
  volume        = {1},
  year          = {2019},
  bdsk-url-1    = {https://doi.org/10.1007/s42399-019-00053-w}
}

@article{simbased-inf,
  author    = {Cranmer, Kyle and Brehmer, Johann and Louppe, Gilles},
  title     = {The frontier of simulation-based inference},
  volume    = {117},
  number    = {48},
  pages     = {30055--30062},
  year      = {2020},
  journal   = {Proceedings of the National Academy of Sciences},
  doi       = {10.1073/pnas.1912789117},
  publisher = {National Academy of Sciences},
  issn      = {0027-8424},
  url       = {https://www.pnas.org/content/117/48/30055},
  eprint    = {https://www.pnas.org/content/117/48/30055.full.pdf}
}


@article{covid-19,
  doi       = {10.1371/journal.pone.0242532},
  author    = {Webb, Jeffrey B. AND Bray, Aaron AND Asare, Philip K. AND Clipp, Rachel B. AND Mehta, Yatin B. AND Penupolu, Sudheer AND Patel, Aalpen A. AND Poler, S. Mark},
  journal   = {PLOS ONE},
  publisher = {Public Library of Science},
  title     = {Computational simulation to assess patient safety of uncompensated COVID-19 two-patient ventilator sharing using the Pulse Physiology Engine},
  year      = {2020},
  month     = {11},
  volume    = {15},
  url       = {https://doi.org/10.1371/journal.pone.0242532},
  pages     = {1-17},
  abstract  = {Background The COVID-19 pandemic is stretching medical resources internationally, sometimes creating ventilator shortages that complicate clinical and ethical situations. The possibility of needing to ventilate multiple patients with a single ventilator raises patient health and safety concerns in addition to clinical conditions needing treatment. Wherever ventilators are employed, additional tubing and splitting adaptors may be available. Adjustable flow-compensating resistance for differences in lung compliance on individual limbs may not be readily implementable. By exploring a number and range of possible contributing factors using computational simulation without risk of patient harm, this paper attempts to define useful bounds for ventilation parameters when compensatory resistance in limbs of a shared breathing circuit is not possible. This desperate approach to shared ventilation support would be a last resort when alternatives have been exhausted.   Methods A whole-body computational physiology model (using lumped parameters) was used to simulate each patient being ventilated. The primary model of a single patient with a dedicated ventilator was augmented to model two patients sharing a single ventilator. In addition to lung mechanics or estimation of CO2 and pH expected for set ventilation parameters (considerations of lung physiology alone), full physiological simulation provides estimates of additional values for oxyhemoglobin saturation, arterial oxygen tension, and other patient parameters. A range of ventilator settings and patient characteristics were simulated for paired patients.   Findings To be useful for clinicians, attention has been directed to clinically available parameters. These simulations show patient outcome during multi-patient ventilation is most closely correlated to lung compliance, oxygenation index, oxygen saturation index, and end-tidal carbon dioxide of individual patients. The simulated patient outcome metrics were satisfactory when the lung compliance difference between two patients was less than 12 mL/cmH2O, and the oxygen saturation index difference was less than 2 mmHg.   Interpretation In resource-limited regions of the world, the COVID-19 pandemic will result in equipment shortages. While single-patient ventilation is preferable, if that option is unavailable and ventilator sharing using limbs without flow resistance compensation is the only available alternative, these simulations provide a conceptual framework and guidelines for clinical patient selection.},
  number    = {11}
}

@article{manski,
  issn      = {00028282},
  url       = {http://www.jstor.org/stable/2006592},
  author    = {Charles F. Manski},
  journal   = {The American Economic Review},
  number    = {2},
  pages     = {319--323},
  publisher = {American Economic Association},
  title     = {Nonparametric Bounds on Treatment Effects},
  urldate   = {2022-06-24},
  volume    = {80},
  year      = {1990}
}
@inproceedings{bareinboim,
  author    = {Zhang, Junzhe and Bareinboim, Elias},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes},
  url       = {https://proceedings.neurips.cc/paper/2019/file/8252831b9fce7a49421e622c14ce0f65-Paper.pdf},
  volume    = {32},
  year      = {2019}
}
@inproceedings{tran2018implicit,
  title     = {Implicit Causal Models for Genome-wide Association Studies},
  author    = {Dustin Tran and David M. Blei},
  booktitle = {International Conference on Learning Representations},
  year      = {2018},
  url       = {https://openreview.net/forum?id=SyELrEeAb}
}


@inproceedings{pmlr-v106-zhang19a,
  title     = {The Medical Deconfounder: Assessing Treatment Effects with Electronic Health Records},
  author    = {Zhang, Linying and Wang, Yixin and Ostropolets, Anna and Mulgrave, Jami J. and Blei, David M. and Hripcsak, George},
  booktitle = {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages     = {490--512},
  year      = {2019},
  editor    = {Finale Doshi-Velez and Jim Fackler and Ken Jung and David Kale and Rajesh Ranganath and Byron Wallace and Jenna Wiens},
  volume    = {106},
  series    = {Proceedings of Machine Learning Research},
  address   = {Ann Arbor, Michigan},
  month     = {09--10 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v106/zhang19a/zhang19a.pdf},
  url       = {http://proceedings.mlr.press/v106/zhang19a.html}
}



@article{sepsis-modelling,
  author  = {McDaniel, Matthew and Keller, Jonathan M. and White, Steven and Baird, Austin},
  title   = {{A Whole-Body Mathematical Model of Sepsis Progression and Treatment Designed in the BioGears Physiology Engine}},
  journal = {Frontiers in Physiology},
  volume  = {10},
  pages   = {1321},
  year    = {2019},
  url     = {https://www.frontiersin.org/article/10.3389/fphys.2019.01321},
  doi     = {10.3389/fphys.2019.01321},
  issn    = {1664-042X}
}

@article{baird2020biogears,
  doi       = {10.21105/joss.02645},
  url       = {https://doi.org/10.21105/joss.02645},
  year      = {2020},
  publisher = {The Open Journal},
  volume    = {5},
  number    = {56},
  pages     = {2645},
  author    = {Austin Baird and Matthew McDaniel and Steven A. White and Nathan Tatum and Lucas Marin},
  title     = {{BioGears: A C++ library for whole body physiology simulations}},
  journal   = {Journal of Open Source Software}
}

@article{pulse-advances,
  author  = {Clipp, R. B. P. and Bray, A. and Feiger and Bradley, P. and Qureshi, Umar M., P. and Webb, J. B.},
  title   = {Recent Advances in the Pulse Physiology Engine},
  journal = {SIAM Conference on Computational Science and Engineering (CSE21)},
  year    = {2021}
}

@inproceedings{rlcyclegan,
  author    = {Rao, Kanishka and Harris, Chris and Irpan, Alex and Levine, Sergey and Ibarz, Julian and Khansari, Mohi},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {RL-CycleGAN: Reinforcement Learning Aware Simulation-to-Real},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {11154-11163},
  doi       = {10.1109/CVPR42600.2020.01117}
}


@inproceedings{tobin2017domain,
  author    = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Domain randomization for transferring deep neural networks from simulation to the real world},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {23-30},
  doi       = {10.1109/IROS.2017.8202133}
}
 

@article{mimic,
  abstract      = {MIMIC-III (`Medical Information Mart for Intensive Care') is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
  author        = {Johnson, Alistair E. W. and Pollard, Tom J. and Shen, Lu and Lehman, Li-wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G.},
  da            = {2016/05/24},
  date-added    = {2022-12-02 19:41:57 +0000},
  date-modified = {2022-12-02 19:41:57 +0000},
  doi           = {10.1038/sdata.2016.35},
  id            = {Johnson2016},
  isbn          = {2052-4463},
  journal       = {Scientific Data},
  number        = {1},
  pages         = {160035},
  title         = {MIMIC-III, a freely accessible critical care database},
  ty            = {JOUR},
  url           = {https://doi.org/10.1038/sdata.2016.35},
  volume        = {3},
  year          = {2016},
  bdsk-url-1    = {https://doi.org/10.1038/sdata.2016.35}
}


@article{sepsis-criteria,
  author   = {Singer, Mervyn and Deutschman, Clifford S. and Seymour, Christopher Warren and Shankar-Hari, Manu and Annane, Djillali and Bauer, Michael and Bellomo, Rinaldo and Bernard, Gordon R. and Chiche, Jean-Daniel and Coopersmith, Craig M. and Hotchkiss, Richard S. and Levy, Mitchell M. and Marshall, John C. and Martin, Greg S. and Opal, Steven M. and Rubenfeld, Gordon D. and van der Poll, Tom and Vincent, Jean-Louis and Angus, Derek C.},
  title    = {{The Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3)}},
  journal  = {JAMA},
  volume   = {315},
  number   = {8},
  pages    = {801-810},
  year     = {2016},
  month    = {02},
  abstract = {{Definitions of sepsis and septic shock were last revised in 2001. Considerable advances have since been made into the pathobiology (changes in organ function, morphology, cell biology, biochemistry, immunology, and circulation), management, and epidemiology of sepsis, suggesting the need for reexamination.To evaluate and, as needed, update definitions for sepsis and septic shock.A task force (n = 19) with expertise in sepsis pathobiology, clinical trials, and epidemiology was convened by the Society of Critical Care Medicine and the European Society of Intensive Care Medicine. Definitions and clinical criteria were generated through meetings, Delphi processes, analysis of electronic health record databases, and voting, followed by circulation to international professional societies, requesting peer review and endorsement (by 31 societies listed in the Acknowledgment).Limitations of previous definitions included an excessive focus on inflammation, the misleading model that sepsis follows a continuum through severe sepsis to shock, and inadequate specificity and sensitivity of the systemic inflammatory response syndrome (SIRS) criteria. Multiple definitions and terminologies are currently in use for sepsis, septic shock, and organ dysfunction, leading to discrepancies in reported incidence and observed mortality. The task force concluded the term severe sepsis was redundant.Sepsis should be defined as life-threatening organ dysfunction caused by a dysregulated host response to infection. For clinical operationalization, organ dysfunction can be represented by an increase in the Sequential [Sepsis-related] Organ Failure Assessment (SOFA) score of 2 points or more, which is associated with an in-hospital mortality greater than 10\%. Septic shock should be defined as a subset of sepsis in which particularly profound circulatory, cellular, and metabolic abnormalities are associated with a greater risk of mortality than with sepsis alone. Patients with septic shock can be clinically identified by a vasopressor requirement to maintain a mean arterial pressure of 65 mm Hg or greater and serum lactate level greater than 2 mmol/L (\\&gt;18 mg/dL) in the absence of hypovolemia. This combination is associated with hospital mortality rates greater than 40\%. In out-of-hospital, emergency department, or general hospital ward settings, adult patients with suspected infection can be rapidly identified as being more likely to have poor outcomes typical of sepsis if they have at least 2 of the following clinical criteria that together constitute a new bedside clinical score termed quickSOFA (qSOFA): respiratory rate of 22/min or greater, altered mentation, or systolic blood pressure of 100 mm Hg or less.These updated definitions and clinical criteria should replace previous definitions, offer greater consistency for epidemiologic studies and clinical trials, and facilitate earlier recognition and more timely management of patients with sepsis or at risk of developing sepsis.}},
  issn     = {0098-7484},
  doi      = {10.1001/jama.2016.0287},
  url      = {https://doi.org/10.1001/jama.2016.0287},
  eprint   = {https://jamanetwork.com/journals/jama/articlepdf/2492881/jsc160002.pdf}
}

@article{seymour2016assessment,
  author   = {Seymour, Christopher W. and Liu, Vincent X. and Iwashyna, Theodore J. and Brunkhorst, Frank M. and Rea, Thomas D. and Scherag, André and Rubenfeld, Gordon and Kahn, Jeremy M. and Shankar-Hari, Manu and Singer, Mervyn and Deutschman, Clifford S. and Escobar, Gabriel J. and Angus, Derek C.},
  title    = {{Assessment of Clinical Criteria for Sepsis: For the Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3)}},
  journal  = {JAMA},
  volume   = {315},
  number   = {8},
  pages    = {762-774},
  year     = {2016},
  month    = {02},
  abstract = {{The Third International Consensus Definitions Task Force defined sepsis as “life-threatening organ dysfunction due to a dysregulated host response to infection.” The performance of clinical criteria for this sepsis definition is unknown.To evaluate the validity of clinical criteria to identify patients with suspected infection who are at risk of sepsis.Among 1.3 million electronic health record encounters from January 1, 2010, to December 31, 2012, at 12 hospitals in southwestern Pennsylvania, we identified those with suspected infection in whom to compare criteria. Confirmatory analyses were performed in 4 data sets of 706 399 out-of-hospital and hospital encounters at 165 US and non-US hospitals ranging from January 1, 2008, until December 31, 2013.Sequential [Sepsis-related] Organ Failure Assessment (SOFA) score, systemic inflammatory response syndrome (SIRS) criteria, Logistic Organ Dysfunction System (LODS) score, and a new model derived using multivariable logistic regression in a split sample, the quick Sequential [Sepsis-related] Organ Failure Assessment (qSOFA) score (range, 0-3 points, with 1 point each for systolic hypotension [≤100 mm Hg], tachypnea [≥22/min], or altered mentation).For construct validity, pairwise agreement was assessed. For predictive validity, the discrimination for outcomes (primary: in-hospital mortality; secondary: in-hospital mortality or intensive care unit [ICU] length of stay ≥3 days) more common in sepsis than uncomplicated infection was determined. Results were expressed as the fold change in outcome over deciles of baseline risk of death and area under the receiver operating characteristic curve (AUROC).In the primary cohort, 148 907 encounters had suspected infection (n = 74 453 derivation; n = 74 454 validation), of whom 6347 (4\\%) died. Among ICU encounters in the validation cohort (n = 7932 with suspected infection, of whom 1289 [16\\%] died), the predictive validity for in-hospital mortality was lower for SIRS (AUROC = 0.64; 95\\% CI, 0.62-0.66) and qSOFA (AUROC = 0.66; 95\\% CI, 0.64-0.68) vs SOFA (AUROC = 0.74; 95\\% CI, 0.73-0.76; P \\&lt; .001 for both) or LODS (AUROC = 0.75; 95\\% CI, 0.73-0.76; P \\&lt; .001 for both). Among non-ICU encounters in the validation cohort (n = 66 522 with suspected infection, of whom 1886 [3\\%] died), qSOFA had predictive validity (AUROC = 0.81; 95\\% CI, 0.80-0.82) that was greater than SOFA (AUROC = 0.79; 95\\% CI, 0.78-0.80; P \\&lt; .001) and SIRS (AUROC = 0.76; 95\\% CI, 0.75-0.77; P \\&lt; .001). Relative to qSOFA scores lower than 2, encounters with qSOFA scores of 2 or higher had a 3- to 14-fold increase in hospital mortality across baseline risk deciles. Findings were similar in external data sets and for the secondary outcome.Among ICU encounters with suspected infection, the predictive validity for in-hospital mortality of SOFA was not significantly different than the more complex LODS but was statistically greater than SIRS and qSOFA, supporting its use in clinical criteria for sepsis. Among encounters with suspected infection outside of the ICU, the predictive validity for in-hospital mortality of qSOFA was statistically greater than SOFA and SIRS, supporting its use as a prompt to consider possible sepsis.}},
  issn     = {0098-7484},
  doi      = {10.1001/jama.2016.0288},
  url      = {https://doi.org/10.1001/jama.2016.0288},
  eprint   = {https://jamanetwork.com/journals/jama/articlepdf/2492875/joi160006.pdf}
}




@inproceedings{raghu,
  title     = {Continuous State-Space Models for Optimal Sepsis Treatment: a Deep Reinforcement Learning Approach},
  author    = {Raghu, Aniruddh and Komorowski, Matthieu and Celi, Leo Anthony and Szolovits, Peter and Ghassemi, Marzyeh},
  booktitle = {Proceedings of the 2nd Machine Learning for Healthcare Conference},
  pages     = {147--163},
  year      = {2017},
  editor    = {Doshi-Velez, Finale and Fackler, Jim and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume    = {68},
  series    = {Proceedings of Machine Learning Research},
  month     = {18--19 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v68/raghu17a/raghu17a.pdf},
  url       = {https://proceedings.mlr.press/v68/raghu17a.html},
  abstract  = {Sepsis is a leading cause of mortality in intensive care units (ICUs) and costs hospitals billions annually. Treating a septic patient is highly challenging, because individual patients respond very differently to medical interventions and there is no universally agreed-upon treatment for sepsis. Understanding more about a patient’s physiological state at a given time could hold the key to effective treatment policies. In this work, we propose a new approach to deduce optimal treatment policies for septic patients by using continuous state-space models and deep reinforcement learning. Learning treatment policies over continuous state-spaces is important, because doing so allows us to retain more of the patient’s physiological information. Our model is able to learn clinically interpretable treatment policies, similar in important aspects to the treatment policies of physicians. Evaluating our algorithm on past ICU patient data, we find that our model could reduce absolute patient mortality in the hospital by up to 3.6\% over observed clinical policies. The learned treatment policies could be used to aid intensive care clinicians in medical decision making and improve the likelihood of patient survival.}
}


@article{ben-hochberg,
  title     = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
  author    = {Benjamini, Yoav and Hochberg, Yosef},
  journal   = {Journal of the Royal Statistical Society.},
  volume    = {57},
  number    = {1},
  pages     = {289--300},
  year      = {1995},
  publisher = {Wiley Online Library}
}

@article{dt,
  author        = {Niederer, Steven A. and Sacks, Michael S. and Girolami, Mark and Willcox, Karen},
  da            = {2021/05/01},
  date-added    = {2021-09-16 10:47:08 +0000},
  date-modified = {2021-09-16 10:47:08 +0000},
  doi           = {10.1038/s43588-021-00072-5},
  id            = {Niederer2021},
  isbn          = {2662-8457},
  journal       = {Nature Computational Science},
  number        = {5},
  pages         = {313--320},
  title         = {Scaling digital twins from the artisanal to the industrial},
  ty            = {JOUR},
  url           = {https://doi.org/10.1038/s43588-021-00072-5},
  volume        = {1},
  year          = {2021},
  bdsk-url-1    = {https://doi.org/10.1038/s43588-021-00072-5}
}

@article{DT-patient,
  author  = {Lal, Amos and Li, Guangxi and Cubro, Edin and Chalmers, Sarah and Li, Heyi and Herasevich, Vitaly and Dong, Yue and Pickering, Brian and Oguz, Kilickaya and Gajic, Ognjen},
  year    = {2021},
  month   = {01},
  pages   = {611-611},
  title   = {Development and Verification of a Digital Twin Patient Model to Predict Treatment Response in Sepsis},
  volume  = {49},
  journal = {Critical Care Medicine},
  doi     = {10.1097/01.ccm.0000730744.82258.38}
}

@inproceedings{biogears,
  author    = {McDaniel, Matthew and Baird, Austin},
  booktitle = {2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  title     = {{A Full-Body Model of Burn Pathophysiology and Treatment Using the BioGears Engine}},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {261-264},
  doi       = {10.1109/EMBC.2019.8857686}
}

@article{niederer2020creation,
  author   = {Niederer, S. A.  and Aboelkassem, Y.  and Cantwell, C. D.  and Corrado, C.  and Coveney, S.  and Cherry, E. M.  and Delhaas, T.  and Fenton, F. H.  and Panfilov, A. V.  and Pathmanathan, P.  and Plank, G.  and Riabiz, M.  and Roney, C. H.  and dos Santos, R. W.  and Wang, L. },
  title    = {Creation and application of virtual patient cohorts of heart models},
  journal  = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume   = {378},
  number   = {2173},
  pages    = {20190558},
  year     = {2020},
  doi      = {10.1098/rsta.2019.0558},
  url      = {https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2019.0558},
  eprint   = {https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2019.0558},
  abstract = { Patient-specific cardiac models are now being used to guide therapies. The increased use of patient-specific cardiac simulations in clinical care will give rise to the development of virtual cohorts of cardiac models. These cohorts will allow cardiac simulations to capture and quantify inter-patient variability. However, the development of virtual cohorts of cardiac models will require the transformation of cardiac modelling from small numbers of bespoke models to robust and rapid workflows that can create large numbers of models. In this review, we describe the state of the art in virtual cohorts of cardiac models, the process of creating virtual cohorts of cardiac models, and how to generate the individual cohort member models, followed by a discussion of the potential and future applications of virtual cohorts of cardiac models. This article is part of the theme issue ‘Uncertainty quantification in cardiac and cardiovascular modelling and simulation’. }
}

@article{molecular_dyn,
  author   = {Wan, Shunzhou  and Sinclair, Robert C.  and Coveney, Peter V. },
  title    = {Uncertainty quantification in classical molecular dynamics},
  journal  = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume   = {379},
  number   = {2197},
  pages    = {20200082},
  year     = {2021},
  doi      = {10.1098/rsta.2020.0082},
  url      = {https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2020.0082},
  eprint   = {https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2020.0082},
  abstract = { Molecular dynamics simulation is now a widespread approach for understanding complex systems on the atomistic scale. It finds applications from physics and chemistry to engineering, life and medical science. In the last decade, the approach has begun to advance from being a computer-based means of rationalizing experimental observations to producing apparently credible predictions for a number of real-world applications within industrial sectors such as advanced materials and drug discovery. However, key aspects concerning the reproducibility of the method have not kept pace with the speed of its uptake in the scientific community. Here, we present a discussion of uncertainty quantification for molecular dynamics simulation designed to endow the method with better error estimates that will enable it to be used to report actionable results. The approach adopted is a standard one in the field of uncertainty quantification, namely using ensemble methods, in which a sufficiently large number of replicas are run concurrently, from which reliable statistics can be extracted. Indeed, because molecular dynamics is intrinsically chaotic, the need to use ensemble methods is fundamental and holds regardless of the duration of the simulations performed. We discuss the approach and illustrate it in a range of applications from materials science to ligand–protein binding free energy estimation. This article is part of the theme issue ‘Reliability and reproducibility in computational science: implementing verification, validation and uncertainty quantification in silico’. }
}


@article{rubin1974estimating,
  author  = {Donald B. Rubin},
  title   = {Estimating causal effects of treatments in randomized and nonrandomized studies},
  journal = {Journal of Educational Psychology},
  volume  = {66},
  pages   = {688–701},
  year    = {1974},
  doi     = {https://doi.org/10.1037/h0037350}
}

%%%%%%%%%%%%%%%%%%%% checked until here %%%%%%%%%%%%%%%%%

@article{ai-clinician,
  abstract      = {Sepsis is the third leading cause of death worldwide and the main cause of mortality in hospitals1--3, but the best treatment strategy remains uncertain. In particular, evidence suggests that current practices in the administration of intravenous fluids and vasopressors are suboptimal and likely induce harm in a proportion of patients1,4--6. To tackle this sequential decision-making problem, we developed a reinforcement learning agent, the Artificial Intelligence (AI) Clinician, which extracted implicit knowledge from an amount of patient data that exceeds by many-fold the life-time experience of human clinicians and learned optimal treatment by analyzing a myriad of (mostly suboptimal) treatment decisions. We demonstrate that the value of the AI Clinician's selected treatment is on average reliably higher than human clinicians. In a large validation cohort independent of the training data, mortality was lowest in patients for whom clinicians'actual doses matched the AI decisions. Our model provides individualized and clinically interpretable treatment decisions for sepsis that could improve patient outcomes.},
  author        = {Komorowski, Matthieu and Celi, Leo A. and Badawi, Omar and Gordon, Anthony C. and Faisal, A. Aldo},
  da            = {2018/11/01},
  date-added    = {2021-10-11 13:04:14 +0000},
  date-modified = {2021-10-11 13:04:14 +0000},
  doi           = {10.1038/s41591-018-0213-5},
  id            = {Komorowski2018},
  isbn          = {1546-170X},
  journal       = {Nature Medicine},
  number        = {11},
  pages         = {1716--1720},
  title         = {The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care},
  ty            = {JOUR},
  url           = {https://doi.org/10.1038/s41591-018-0213-5},
  volume        = {24},
  year          = {2018},
  bdsk-url-1    = {https://doi.org/10.1038/s41591-018-0213-5}
}

@article{qlearning,
  abstract      = {An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
  author        = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  da            = {2015/02/01},
  date-added    = {2021-10-30 14:06:50 +0000},
  date-modified = {2021-10-30 14:06:50 +0000},
  doi           = {10.1038/nature14236},
  id            = {Mnih2015},
  isbn          = {1476-4687},
  journal       = {Nature},
  number        = {7540},
  pages         = {529--533},
  title         = {Human-level control through deep reinforcement learning},
  ty            = {JOUR},
  url           = {https://doi.org/10.1038/nature14236},
  volume        = {518},
  year          = {2015},
  bdsk-url-1    = {https://doi.org/10.1038/nature14236}
}

@inproceedings{kmeans,
  author    = {Arthur, David and Vassilvitskii, Sergei},
  title     = {K-Means++: The Advantages of Careful Seeding},
  year      = {2007},
  isbn      = {9780898716245},
  publisher = {Society for Industrial and Applied Mathematics},
  address   = {USA},
  abstract  = {The k-means method is a widely used clustering technique that seeks to minimize the average squared distance between points in the same cluster. Although it offers no accuracy guarantees, its simplicity and speed are very appealing in practice. By augmenting k-means with a very simple, randomized seeding technique, we obtain an algorithm that is Θ(logk)-competitive with the optimal clustering. Preliminary experiments show that our augmentation improves both the speed and the accuracy of k-means, often quite dramatically.},
  booktitle = {Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages     = {1027–1035},
  numpages  = {9},
  location  = {New Orleans, Louisiana},
  series    = {SODA '07}
}


@article{slln-bootstrap,
  title    = {On the law of large numbers for the bootstrap mean},
  journal  = {Statistics & Probability Letters},
  volume   = {14},
  number   = {1},
  pages    = {1-7},
  year     = {1992},
  issn     = {0167-7152},
  doi      = {https://doi.org/10.1016/0167-7152(92)90203-H},
  url      = {https://www.sciencedirect.com/science/article/pii/016771529290203H},
  author   = {Sándor Csörgo},
  keywords = {Bootstrap, sample mean, law of large numbers},
  abstract = {Direct and elementary proofs are given for weak and strong laws of large numbers for bootstrap sample means under minimal moment conditions. Concerning the required rate of divergence of the bootstrap sample size, the strong laws obtained improve on those of Athreya (1983). Ams 1980 Subject Classifications: Primary 60F15; Secondary 62G05}
}

@book{dudley2018real,
  title     = {Real analysis and probability},
  author    = {Dudley, Richard M},
  year      = {2018},
  publisher = {CRC Press}
}

@book{tsiatis2019dynamic,
  title     = {Dynamic treatment regimes: Statistical methods for precision medicine},
  author    = {Tsiatis, Anastasios A and Davidian, Marie and Holloway, Shannon T and Laber, Eric B},
  year      = {2019},
  publisher = {Chapman and Hall/CRC}
}

@article{murphy2003optimal,
  title     = {Optimal dynamic treatment regimes},
  author    = {Murphy, Susan A},
  journal   = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume    = {65},
  number    = {2},
  pages     = {331--355},
  year      = {2003},
  publisher = {Wiley Online Library}
}

@article{murphy2005experimental,
  author   = {Murphy, S. A.},
  title    = {An experimental design for the development of adaptive treatment strategies},
  journal  = {Statistics in Medicine},
  volume   = {24},
  number   = {10},
  pages    = {1455-1481},
  keywords = {therapeutic strategies, treatment algorithms, sequential multiple assignment randomized trial, multi-stage decision problems, dynamic treatment regimes},
  doi      = {https://doi.org/10.1002/sim.2022},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2022},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2022},
  abstract = {Abstract In adaptive treatment strategies, the treatment level and type is repeatedly adjusted according to ongoing individual response. Since past treatment may have delayed effects, the development of these treatment strategies is challenging. This paper advocates the use of sequential multiple assignment randomized trials in the development of adaptive treatment strategies. Both a simple ad hoc method for ascertaining sample sizes and simple analysis methods are provided. Copyright © 2004 John Wiley \& Sons, Ltd.},
  year     = {2005}
}

@article{lavori2004dynamic,
  title     = {Dynamic treatment regimes: practical design considerations},
  author    = {Lavori, Philip W and Dawson, Ree},
  journal   = {Clinical trials},
  volume    = {1},
  number    = {1},
  pages     = {9--20},
  year      = {2004},
  publisher = {Sage Publications Sage CA: Thousand Oaks, CA}
}


@inproceedings{alaa2019validating,
  title        = {Validating causal inference models via influence functions},
  author       = {Alaa, Ahmed and Van Der Schaar, Mihaela},
  booktitle    = {International Conference on Machine Learning},
  pages        = {191--201},
  year         = {2019},
  organization = {PMLR}
}

@book{popper2005logic,
  title     = {The Logic of Scientific Discovery},
  author    = {Popper, Karl},
  year      = {2005},
  publisher = {Routledge}
}

@inproceedings{parikh2022validating,
  title     = {Validating Causal Inference Methods},
  author    = {Parikh, Harsh and Varjao, Carlos and Xu, Louise and Tchetgen, Eric Tchetgen},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning},
  pages     = {17346--17358},
  year      = {2022},
  editor    = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume    = {162},
  series    = {Proceedings of Machine Learning Research},
  month     = {17--23 Jul},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v162/parikh22a/parikh22a.pdf},
  url       = {https://proceedings.mlr.press/v162/parikh22a.html},
  abstract  = {The fundamental challenge of drawing causal inference is that counterfactual outcomes are not fully observed for any unit. Furthermore, in observational studies, treatment assignment is likely to be confounded. Many statistical methods have emerged for causal inference under unconfoundedness conditions given pre-treatment covariates, including propensity score-based methods, prognostic score-based methods, and doubly robust methods. Unfortunately for applied researchers, there is no ‘one-size-fits-all’ causal method that can perform optimally universally. In practice, causal methods are primarily evaluated quantitatively on handcrafted simulated data. Such data-generative procedures can be of limited value because they are typically stylized models of reality. They are simplified for tractability and lack the complexities of real-world data. For applied researchers, it is critical to understand how well a method performs for the data at hand. Our work introduces a deep generative model-based framework, Credence, to validate causal inference methods. The framework’s novelty stems from its ability to generate synthetic data anchored at the empirical distribution for the observed sample, and therefore virtually indistinguishable from the latter. The approach allows the user to specify ground truth for the form and magnitude of causal effects and confounding bias as functions of covariates. Thus simulated data sets are used to evaluate the potential performance of various causal estimation methods when applied to data similar to the observed sample. We demonstrate Credence’s ability to accurately assess the relative performance of causal estimation techniques in an extensive simulation study and two real-world data applications from Lalonde and Project STAR studies.}
}

@book{davison1997bootstrap,
  place      = {Cambridge},
  series     = {Cambridge Series in Statistical and Probabilistic Mathematics},
  title      = {Bootstrap Methods and their Application},
  doi        = {10.1017/CBO9780511802843},
  publisher  = {Cambridge University Press},
  author     = {Davison, A. C. and Hinkley, D. V.},
  year       = {1997},
  collection = {Cambridge Series in Statistical and Probabilistic Mathematics}
}


@article{tibshirani1993introduction,
  title     = {An Introduction to the Bootstrap},
  author    = {Tibshirani, Robert J and Efron, Bradley},
  journal   = {Monographs on statistics and applied probability},
  volume    = {57},
  pages     = {1--436},
  year      = {1993},
  publisher = {Chapman and Hall/CRC}
}

@article{hesterberg2015what,
  author    = {Tim C. Hesterberg},
  title     = {What Teachers Should Know About the Bootstrap: Resampling in the Undergraduate Statistics Curriculum},
  journal   = {The American Statistician},
  volume    = {69},
  number    = {4},
  pages     = {371-386},
  year      = {2015},
  publisher = {Taylor & Francis},
  doi       = {10.1080/00031305.2015.1089789},
  note      = {PMID: 27019512},
  url       = {https://doi.org/10.1080/00031305.2015.1089789},
  eprint    = {https://doi.org/10.1080/00031305.2015.1089789}
}

@article{efron1979bootstrap,
  author    = {B. Efron},
  title     = {Bootstrap Methods: Another Look at the Jackknife},
  volume    = {7},
  journal   = {The Annals of Statistics},
  number    = {1},
  publisher = {Institute of Mathematical Statistics},
  pages     = {1 -- 26},
  keywords  = {bootstrap, discriminant analysis, error rate estimation, jackknife, Nonlinear regression, nonparametric variance estimation, Resampling, subsample values},
  year      = {1979},
  doi       = {10.1214/aos/1176344552},
  url       = {https://doi.org/10.1214/aos/1176344552}
}

@article{hall1988theoretical,
  author    = {Peter Hall},
  title     = {Theoretical Comparison of Bootstrap Confidence Intervals},
  volume    = {16},
  journal   = {The Annals of Statistics},
  number    = {3},
  publisher = {Institute of Mathematical Statistics},
  pages     = {927 -- 953},
  keywords  = {Acceleration constant, bias-correction, bootstrap, Confidence interval, coverage, critical point, interval length, nonparametric bootstrap, Parametric bootstrap, percentile-method, quantile, shortest confidence interval},
  year      = {1988},
  doi       = {10.1214/aos/1176350933},
  url       = {https://doi.org/10.1214/aos/1176350933}
}

@article{benjamini2001control,
  author    = {Yoav Benjamini and Daniel Yekutieli},
  title     = {The control of the false discovery rate in multiple testing under dependency},
  volume    = {29},
  journal   = {The Annals of Statistics},
  number    = {4},
  publisher = {Institute of Mathematical Statistics},
  pages     = {1165 -- 1188},
  keywords  = {comparisons with control, discrete test statistics, FDR, Hochberg’s procedure, MTP2 densities, Multiple comparisons procedures, multiple endpoints many-to-one comparisons, positive regression dependency, Simes’equality, unidimensional latent variables},
  year      = {2001},
  doi       = {10.1214/aos/1013699998},
  url       = {https://doi.org/10.1214/aos/1013699998}
}

@article{holm1979simple,
  issn      = {03036898, 14679469},
  url       = {http://www.jstor.org/stable/4615733},
  abstract  = {This paper presents a simple and widely applicable multiple test procedure of the sequentially rejective type, i.e. hypotheses are rejected one at a time until no further rejections can be done. It is shown that the test has a prescribed level of significance protection against error of the first kind for any combination of true hypotheses. The power properties of the test and a number of possible applications are also discussed.},
  author    = {Sture Holm},
  journal   = {Scandinavian Journal of Statistics},
  number    = {2},
  pages     = {65--70},
  publisher = {[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley]},
  title     = {A Simple Sequentially Rejective Multiple Test Procedure},
  urldate   = {2022-12-13},
  volume    = {6},
  year      = {1979}
}

@book{chakraborty2013statistical,
  title     = {Statistical Methods for Dynamic Treatment Regimes: Reinforcement Learning, Causal Inference, and Personalized Medicine},
  author    = {Bibhas Chakraborty, Erica E.M. Moodie (auth.)},
  publisher = {Springer-Verlag New York},
  isbn      = {978-1-4614-7427-2,978-1-4614-7428-9},
  year      = {2013},
  series    = {Statistics for Biology and Health},
  edition   = {1},
  volume    = {},
  url       = {http://gen.lib.rus.ec/book/index.php?md5=26b199f03589d21210940fa97a84913c}
}

@article{farewell2017ignorability,
  title     = {Ignorability for general longitudinal data},
  author    = {Farewell, DM and Huang, C and Didelez, V},
  journal   = {Biometrika},
  volume    = {104},
  number    = {2},
  pages     = {317--326},
  year      = {2017},
  publisher = {Oxford University Press}
}

@book{kallenberg1997foundations,
  title     = {Foundations of Modern Probability},
  author    = {Kallenberg, Olav and Kallenberg, Olav},
  volume    = {2},
  year      = {1997},
  publisher = {Springer}
}


@article{rubin2005causal,
  author    = {Donald B Rubin},
  title     = {Causal Inference Using Potential Outcomes},
  journal   = {Journal of the American Statistical Association},
  volume    = {100},
  number    = {469},
  pages     = {322-331},
  year      = {2005},
  publisher = {Taylor \& Francis},
  doi       = {10.1198/016214504000001880},
  url       = {https://doi.org/10.1198/016214504000001880},
  eprint    = {https://doi.org/10.1198/016214504000001880}
}

%%%%%%%%%%%%%%%%%%%%%%% checked till here %%%%%%%%%%%%%%%%%%
@article{rubin1980randomization,
  issn      = {01621459},
  url       = {http://www.jstor.org/stable/2287648},
  abstract  = {R. A. Fisher's classic text on the design of experiments is the principal source of inspiration for a model of data interpretation that is usually characterized as randomization analysis. In Chapter III of this text, Fisher briefly commented on how to make a randomization test on some data generated by a Darwin experiment. Two variants of this randomization test are discussed in this article. The variant that is discussed in Section 4 may be regarded as the forerunner of all nonparametric tests. The original variant of the test is discussed in Section 6. The author concludes that the Fisher randomization test is not logically viable.},
  author    = {D. Basu},
  journal   = {Journal of the American Statistical Association},
  number    = {371},
  pages     = {575--582},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  title     = {Randomization Analysis of Experimental Data: The Fisher Randomization Test},
  urldate   = {2022-12-13},
  volume    = {75},
  year      = {1980}
}

@article{holland1986statistics,
  issn      = {01621459},
  url       = {http://www.jstor.org/stable/2289064},
  abstract  = {Problems involving causal inference have dogged at the heels of statistics since its earliest days. Correlation does not imply causation, and yet causal conclusions drawn from a carefully designed experiment are often valid. What can a statistical model say about causation? This question is addressed by using a particular model for causal inference (Holland and Rubin 1983; Rubin 1974) to critique the discussions of other writers on causation and causal inference. These include selected philosophers, medical researchers, statisticians, econometricians, and proponents of causal modeling.},
  author    = {Paul W. Holland},
  journal   = {Journal of the American Statistical Association},
  number    = {396},
  pages     = {945--960},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  title     = {Statistics and Causal Inference},
  urldate   = {2022-12-13},
  volume    = {81},
  year      = {1986}
}

@article{rosenbaum1983central,
  issn      = {00063444},
  url       = {http://www.jstor.org/stable/2335942},
  abstract  = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two-dimensional plot.},
  author    = {Paul R. Rosenbaum and Donald B. Rubin},
  journal   = {Biometrika},
  number    = {1},
  pages     = {41--55},
  publisher = {[Oxford University Press, Biometrika Trust]},
  title     = {The Central Role of the Propensity Score in Observational Studies for Causal Effects},
  urldate   = {2022-12-13},
  volume    = {70},
  year      = {1983}
}


@article{imbens2020potential,
  title   = {Potential outcome and directed acyclic graph approaches to causality: Relevance for empirical practice in economics},
  author  = {Imbens, Guido W},
  journal = {Journal of Economic Literature},
  volume  = {58},
  number  = {4},
  pages   = {1129--79},
  year    = {2020}
}

@book{williams1991probability,
  place     = {Cambridge},
  title     = {Probability with Martingales},
  doi       = {10.1017/CBO9780511813658},
  publisher = {Cambridge University Press},
  author    = {Williams, David},
  year      = {1991}
}

@book{manski2009identification,
  title     = {Identification for Prediction and Decision},
  author    = {Manski, Charles F},
  year      = {2009},
  publisher = {Harvard University Press}
}

@book{manski2003partial,
  title     = {Partial Identification of Probability Distributions},
  author    = {Manski, Charles F},
  year      = {2003},
  publisher = {Springer}
}

@article{manski1989anatomy,
  issn      = {0022166X},
  url       = {http://www.jstor.org/stable/145818},
  abstract  = {This article considers anew the problem of estimating a regression E(y|x) when realizations of (y, x) are sampled randomly but y is observed selectively. The central issue is the failure of the sampling process to identify E(y|x). The problem faced by the researcher is to find correct prior restrictions which, when combined with the data, identify the regression. Two kinds of restrictions are examined here. One, which has not been studied before, is a bound on the support of y. Such a bound implies a simple, useful bound on E(y|x). The other, which has received much attention, is a separability restriction derived from a latent variable model.},
  author    = {Charles F. Manski},
  journal   = {The Journal of Human Resources},
  number    = {3},
  pages     = {343--360},
  publisher = {[University of Wisconsin Press, Board of Regents of the University of Wisconsin System]},
  title     = {Anatomy of the Selection Problem},
  urldate   = {2022-12-13},
  volume    = {24},
  year      = {1989}
}

@article{balke1997bounds,
  author    = {Alexander   Balke  and  Judea   Pearl},
  title     = {Bounds on Treatment Effects from Studies with Imperfect Compliance},
  journal   = {Journal of the American Statistical Association},
  volume    = {92},
  number    = {439},
  pages     = {1171-1176},
  year      = {1997},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/01621459.1997.10474074},
  url       = {https://doi.org/10.1080/01621459.1997.10474074
               },
  eprint    = {https://doi.org/10.1080/01621459.1997.10474074
               }
}

@misc{manski1998monotone,
  title     = {Monotone Instrumental Variables with an Application to the Returns to Schooling},
  author    = {Manski, Charles F and Pepper, John V},
  year      = {1998},
  publisher = {National Bureau of Economic Research Cambridge, Mass., USA}
}

@article{manski2000monotone,
  issn      = {00129682, 14680262},
  url       = {http://www.jstor.org/stable/2999533},
  author    = {Charles F. Manski and John V. Pepper},
  journal   = {Econometrica},
  number    = {4},
  pages     = {997--1010},
  publisher = {[Wiley, Econometric Society]},
  title     = {Monotone Instrumental Variables: With an Application to the Returns to Schooling},
  urldate   = {2022-11-24},
  volume    = {68},
  year      = {2000}
}


@article{manski1997monotone,
  issn      = {00129682, 14680262},
  url       = {http://www.jstor.org/stable/2171738},
  abstract  = {The standard formalization of the econometric analysis of treatment response assumes that each member of a population of interest receives one of a set of mutually exclusive and exhaustive treatments, and that the outcome under the realized treatment is observable. Outcomes under the nonrealized treatments are necessarily unobservable; hence these outcomes are censored. This paper investigates what may be learned about treatment response when it is assumed that response functions are monotone, semi-monotone, or concave-monotone. The analysis assumes nothing about the process of treatment selection and imposes no cross-individual restrictions on response. The basic idea is to determine, for every member of the population, the set of response functions that pass through that person's realized (treatment, outcome) pair and that are consistent with the functional-form assumption imposed. These person-specific findings are then explicitly aggregated across the population to determine what can be learned about the distribution of response. The findings have application to the econometric analysis of market demand and of production.},
  author    = {Charles F. Manski},
  journal   = {Econometrica},
  number    = {6},
  pages     = {1311--1334},
  publisher = {[Wiley, Econometric Society]},
  title     = {Monotone Treatment Response},
  urldate   = {2022-11-24},
  volume    = {65},
  year      = {1997}
}

@article{bauer2021digital,
  title     = {A digital twin of Earth for the green transition},
  author    = {Bauer, Peter and Stevens, Bjorn and Hazeleger, Wilco},
  journal   = {Nature Climate Change},
  volume    = {11},
  number    = {2},
  pages     = {80--83},
  year      = {2021},
  publisher = {Nature Publishing Group}
}

@article{sacks2020construction,
  title     = {Construction with digital twin information systems},
  author    = {Sacks, Rafael and Brilakis, Ioannis and Pikas, Ergo and Xie, Haiyan and Girolami, Mark},
  journal   = {Data-Centric Engineering},
  volume    = {1},
  year      = {2020},
  publisher = {Cambridge University Press}
}

@article{jans2020digital,
  title     = {Digital twin of an urban-integrated hydroponic farm},
  volume    = {1},
  doi       = {10.1017/dce.2020.21},
  journal   = {Data-Centric Engineering},
  publisher = {Cambridge University Press},
  author    = {Jans-Singh, Melanie and Leeming, Kathryn and Choudhary, Ruchi and Girolami, Mark},
  year      = {2020},
  pages     = {e20}
}


@inbook{thuemmler2017health,
  author    = {Thuemmler, Christoph
               and Bai, Chunxue},
  title     = {Health 4.0: Application of Industry 4.0 Design Principles in Future Asthma Management},
  booktitle = {Health 4.0: How Virtualization and Big Data are Revolutionizing Healthcare},
  year      = {2017},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {23--37},
  abstract  = {Industry 4.0 is a well-known industrial concept leveraging individualization and virtualization across different industrial domains. At its core Industry 4.0 empowers industries to evolve from manufacturers to service providers. Recently design principles for Industry 4.0 scenarios have been proposed. This chapter discusses the validity of the design principles for the health domain investigating its suitability for the diagnostics and therapy (theragnostics)  of asthma. We come to the conclusion, that Industry 4.0 design principles work very well in the health domain especially with regards to Precision Medicine and  the rapidly progressive evolution of smart pharmaceuticals Smart pharmaceuticalsin chronic, non-communicable diseases. The concept appears to be suitable for the health domain  but its implementation and uptake will depend on future network specifications and features.},
  isbn      = {978-3-319-47617-9},
  doi       = {10.1007/978-3-319-47617-9_2},
  url       = {https://doi.org/10.1007/978-3-319-47617-9_2}
}


@article{barricelli2019survey,
  title     = {A Survey on Digital Twin: Definitions, Characteristics, Applications, and Design Implications},
  author    = {Barricelli, Barbara Rita and Casiraghi, Elena and Fogli, Daniela},
  journal   = {IEEE access},
  volume    = {7},
  pages     = {167653--167671},
  year      = {2019},
  publisher = {IEEE}
}

@article{zheng2018smart,
  title     = {Smart manufacturing systems for Industry 4.0: Conceptual framework, scenarios, and future perspectives},
  author    = {Zheng, Pai and Sang, Zhiqian and Zhong, Ray Y and Liu, Yongkui and Liu, Chao and Mubarok, Khamdi and Yu, Shiqiang and Xu, Xun and others},
  journal   = {Frontiers of Mechanical Engineering},
  volume    = {13},
  number    = {2},
  pages     = {137--150},
  year      = {2018},
  publisher = {Springer}
}

@article{zhong2017intelligent,
  title     = {Intelligent Manufacturing in the Context of Industry 4.0: A Review},
  author    = {Zhong, Ray Y and Xu, Xun and Klotz, Eberhard and Newman, Stephen T},
  journal   = {Engineering},
  volume    = {3},
  number    = {5},
  pages     = {616--630},
  year      = {2017},
  publisher = {Elsevier}
}

@article{kritzinger2018digital,
  title     = {Digital Twin in manufacturing: A categorical literature review and classification},
  author    = {Kritzinger, Werner and Karner, Matthias and Traar, Georg and Henjes, Jan and Sihn, Wilfried},
  journal   = {IFAC-PapersOnLine},
  volume    = {51},
  number    = {11},
  pages     = {1016--1022},
  year      = {2018},
  publisher = {Elsevier}
}


@article{coorey2021health,
  abstract      = {Precision medicine envisages a changed paradigm for health care through better understanding of individual disease susceptibility and prognosis, enabling more personalized treatment. Enabling technologies such as the health digital twin are rapidly evolving, presenting important challenges and opportunities to be tackled within local contexts.},
  author        = {Coorey, Genevieve and Figtree, Gemma A. and Fletcher, David F. and Redfern, Julie},
  da            = {2021/12/01},
  date-added    = {2022-12-13 15:48:29 +0000},
  date-modified = {2022-12-13 15:48:29 +0000},
  doi           = {10.1038/s41569-021-00630-4},
  id            = {Coorey2021},
  isbn          = {1759-5010},
  journal       = {Nature Reviews Cardiology},
  number        = {12},
  pages         = {803--804},
  title         = {The health digital twin: advancing precision cardiovascular medicine},
  ty            = {JOUR},
  url           = {https://doi.org/10.1038/s41569-021-00630-4},
  volume        = {18},
  year          = {2021},
  bdsk-url-1    = {https://doi.org/10.1038/s41569-021-00630-4}
}

@article{niederer2021scaling,
  title     = {Scaling digital twins from the artisanal to the industrial},
  author    = {Niederer, Steven A and Sacks, Michael S and Girolami, Mark and Willcox, Karen},
  journal   = {Nature Computational Science},
  volume    = {1},
  number    = {5},
  pages     = {313--320},
  year      = {2021},
  publisher = {Nature Publishing Group}
}

@article{jones2020characterising,
  title     = {Characterising the Digital Twin: A systematic literature review},
  author    = {Jones, David and Snider, Chris and Nassehi, Aydin and Yon, Jason and Hicks, Ben},
  journal   = {CIRP Journal of Manufacturing Science and Technology},
  volume    = {29},
  pages     = {36--52},
  year      = {2020},
  publisher = {Elsevier}
}

@article{tuegel2011reengineering,
  abstract      = {Reengineering of the aircraft structural life prediction process to fully exploit advances in very high performance digital computing is proposed. The proposed process utilizes an ultrahigh fidelity model of individual aircraft by tail number, a Digital Twin, to integrate computation of structural deflections and temperatures in response to flight conditions, with resulting local damage and material state evolution. A conceptual model of how the Digital Twin can be used for predicting the life of aircraft structure and assuring its structural integrity is presented. The technical challenges to developing and deploying a Digital Twin are discussed in detail.},
  author        = {Bellinger, Nicholas and Tuegel, Eric J. and Ingraffea, Anthony R. and Eason, Thomas G. and Spottswood, S. Michael},
  da            = {2011/10/23},
  date-added    = {2022-12-13 15:49:51 +0000},
  date-modified = {2022-12-13 15:49:51 +0000},
  doi           = {10.1155/2011/154798},
  isbn          = {1687-5966},
  journal       = {International Journal of Aerospace Engineering},
  pages         = {154798},
  publisher     = {Hindawi Publishing Corporation},
  title         = {Reengineering Aircraft Structural Life Prediction Using a Digital Twin},
  ty            = {JOUR},
  url           = {https://doi.org/10.1155/2011/154798},
  volume        = {2011},
  year          = {2011},
  bdsk-url-1    = {https://doi.org/10.1155/2011/154798}
}

@article{corral2020digital,
  title     = {The 'Digital Twin' to enable the vision of precision cardiology},
  author    = {Corral-Acero, Jorge and Margara, Francesca and Marciniak, Maciej and Rodero, Cristobal and Loncaric, Filip and Feng, Yingjing and Gilbert, Andrew and Fernandes, Joao F and Bukhari, Hassaan A and Wajdan, Ali and others},
  journal   = {European Heart Journal},
  volume    = {41},
  number    = {48},
  pages     = {4556--4564},
  year      = {2020},
  publisher = {Oxford University Press}
}

@article{lu2020digital,
  title     = {Digital Twin-driven smart manufacturing: Connotation, reference model, applications and research issues},
  author    = {Lu, Yuqian and Liu, Chao and Kevin, I and Wang, Kai and Huang, Huiyue and Xu, Xun},
  journal   = {Robotics and Computer-Integrated Manufacturing},
  volume    = {61},
  pages     = {101837},
  year      = {2020},
  publisher = {Elsevier}
}


@article{roy2011comprehensive,
  title    = {A comprehensive framework for verification, validation, and uncertainty quantification in scientific computing},
  journal  = {Computer Methods in Applied Mechanics and Engineering},
  volume   = {200},
  number   = {25},
  pages    = {2131-2144},
  year     = {2011},
  issn     = {0045-7825},
  doi      = {https://doi.org/10.1016/j.cma.2011.03.016},
  url      = {https://www.sciencedirect.com/science/article/pii/S0045782511001290},
  author   = {Christopher J. Roy and William L. Oberkampf},
  keywords = {Uncertainty quantification, Verification, Validation, Modeling, Computational simulation},
  abstract = {An overview of a comprehensive framework is given for estimating the predictive uncertainty of scientific computing applications. The framework is comprehensive in the sense that it treats both types of uncertainty (aleatory and epistemic), incorporates uncertainty due to the mathematical form of the model, and it provides a procedure for including estimates of numerical error in the predictive uncertainty. Aleatory (random) uncertainties in model inputs are treated as random variables, while epistemic (lack of knowledge) uncertainties are treated as intervals with no assumed probability distributions. Approaches for propagating both types of uncertainties through the model to the system response quantities of interest are briefly discussed. Numerical approximation errors (due to discretization, iteration, and computer round off) are estimated using verification techniques, and the conversion of these errors into epistemic uncertainties is discussed. Model form uncertainty is quantified using (a) model validation procedures, i.e., statistical comparisons of model predictions to available experimental data, and (b) extrapolation of this uncertainty structure to points in the application domain where experimental data do not exist. Finally, methods for conveying the total predictive uncertainty to decision makers are presented. The different steps in the predictive uncertainty framework are illustrated using a simple example in computational fluid dynamics applied to a hypersonic wind tunnel.}
}

@article{galappaththige2022credibility,
  title     = {Credibility assessment of patient-specific computational modeling using patient-specific cardiac modeling as an exemplar},
  author    = {Galappaththige, Suran and Gray, Richard A and Costa, Caroline Mendonca and Niederer, Steven and Pathmanathan, Pras},
  journal   = {PLoS computational biology},
  volume    = {18},
  number    = {10},
  pages     = {e1010541},
  year      = {2022},
  publisher = {Public Library of Science San Francisco, CA USA}
}


@book{amse2018assessing,
  title     = {Assessing Credibility of Computational Modeling through Verification and Validation: Application to Medical Devices},
  author    = {AMSE},
  year      = {2018},
  publisher = {AMSE}
}


@article{morrison2018advancing,
  title     = {Advancing regulatory science with computational modeling for medical devices at the FDA's office of science and engineering laboratories},
  author    = {Morrison, Tina M and Pathmanathan, Pras and Adwan, Mariam and Margerrison, Edward},
  journal   = {Frontiers in medicine},
  volume    = {5},
  pages     = {241},
  year      = {2018},
  publisher = {Frontiers Media SA}
}
@article{dahmen2022verification,
  author    = {Dahmen, Ulrich Richard and Osterloh, Tobias and Roßmann,
               Heinz-Jürgen},
  title     = {Verification and validation of digital twins and virtual
               testbeds},
  journal   = {International journal of advances in engineering sciences
               and applied mathematics},
  volume    = {11},
  number    = {1},
  issn      = {0975-5616},
  address   = {[New Delhi]},
  publisher = {Springer India},
  reportid  = {RWTH-2022-03221},
  pages     = {47-64},
  year      = {2022},
  cin       = {615210},
  cid       = {$I:(DE-82)615210_20140620$},
  typ       = {PUB:(DE-HGF)16},
  doi       = {10.11591/ijaas.v11.i1.pp47-64},
  url       = {https://publications.rwth-aachen.de/record/843535}
}

@article{tao2018digital,
  title     = {Digital twin in industry: State-of-the-art},
  author    = {Tao, Fei and Zhang, He and Liu, Ang and Nee, Andrew YC},
  journal   = {IEEE Transactions on Industrial Informatics},
  volume    = {15},
  number    = {4},
  pages     = {2405--2415},
  year      = {2018},
  publisher = {IEEE}
}

@inproceedings{khan2018digital,
  title        = {Digital twin for legacy systems: Simulation model testing and validation},
  author       = {Khan, Adnan and Dahl, Martin and Falkman, Petter and Fabian, Martin},
  booktitle    = {2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)},
  year         = {2018},
  organization = {IEEE}
}

@article{hemmler2019patient,
  title     = {Patient-specific in silico endovascular repair of abdominal aortic aneurysms: application and validation},
  author    = {Hemmler, Andr{\'e} and Lutz, Brigitta and Kalender, G{\"u}nay and Reeps, Christian and Gee, Michael W},
  journal   = {Biomechanics and Modeling in Mechanobiology},
  volume    = {18},
  number    = {4},
  pages     = {983--1004},
  year      = {2019},
  publisher = {Springer}
}

@article{larrabide2012fast,
  title   = {Fast virtual deployment of self-expandable stents: method and in vitro evaluation for intracranial aneurysmal stenting},
  author  = {Larrabide, Ignacio and Kim, Minsuok and Augsburger, Luca and Villa-Uriol, Maria Cruz and Rüfenacht, Daniel and Frangi, Alejandro F},
  doi     = {10.1016/j.media.2010.04.009},
  number  = {3},
  volume  = {16},
  month   = {April},
  year    = {2012},
  journal = {Medical Image Analysis},
  issn    = {1361-8415},
  pages   = {721—730},
  url     = {https://doi.org/10.1016/j.media.2010.04.009}
}

@inproceedings{mazumder2019synthetic,
  author    = {Mazumder, Oishee and Roy, Dibyendu and Bhattacharya, Sakyajit and Sinha, Aniruddha and Pal, Arpan},
  booktitle = {2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  title     = {Synthetic {PPG} generation from haemodynamic model with baroreflex autoregulation: a {Digital} twin of cardiovascular system},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {5024-5029},
  doi       = {10.1109/EMBC.2019.8856691}
}

@article{coorey2022health,
  title     = {The health digital twin to tackle cardiovascular disease—a review of an emerging interdisciplinary field},
  author    = {Coorey, Genevieve and Figtree, Gemma A and Fletcher, David F and Snelson, Victoria J and Vernon, Stephen Thomas and Winlaw, David and Grieve, Stuart M and McEwan, Alistair and Yang, Jean Yee Hwa and Qian, Pierre and others},
  journal   = {NPJ Digital Medicine},
  year      = {2022},
  publisher = {Nature Publishing Group}
}

@article{kochunas2021digital,
  title     = {Digital Twin Concepts with Uncertainty for Nuclear Power Applications},
  author    = {Kochunas, Brendan and Huan, Xun},
  journal   = {Energies},
  volume    = {14},
  number    = {14},
  pages     = {4235},
  year      = {2021},
  publisher = {MDPI}
}

@incollection{grieves2017digital,
  title     = {Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems},
  author    = {Grieves, Michael and Vickers, John},
  booktitle = {Transdisciplinary Perspectives on Complex Systems},
  pages     = {85--113},
  year      = {2017},
  publisher = {Springer}
}

@article{kapteyn2021probabilistic,
  title     = {A probabilistic graphical model foundation for enabling predictive digital twins at scale},
  author    = {Kapteyn, Michael G and Pretorius, Jacob VR and Willcox, Karen E},
  journal   = {Nature Computational Science},
  volume    = {1},
  number    = {5},
  pages     = {337--347},
  year      = {2021},
  publisher = {Nature Publishing Group}
}

@article{masison2021modular,
  title     = {A modular computational framework for medical digital twins},
  author    = {Masison, Joseph and Beezley, Jonathan and Mei, Yu and Ribeiro, Henrique Assis Lopes and Knapp, Adam C and Sordo Vieira, L and Adhikari, Bandita and Scindia, Yogesh and Grauer, Michael and Helba, Brian and others},
  journal   = {Proceedings of the National Academy of Sciences},
  volume    = {118},
  number    = {20},
  pages     = {e2024287118},
  year      = {2021},
  publisher = {National Acad Sciences}
}

@book{hernan2020causal,
  title     = {Causal Inference: What If},
  author    = {Hern{\'a}n, Miguel A and Robins, James M},
  year      = {2020},
  publisher = {Chapman and Hall/CRC},
  address   = {Boca Raton}
}


@article{marcus1976method,
  issn      = {00063444},
  url       = {http://www.jstor.org/stable/2335748},
  abstract  = {A method of devising stepwise multiple testing procedures with fixed experimentwise error is presented. The method requires the set of hypotheses tested to be closed under intersection. The method is applied to the problem of comparing many treatments to one control and to ordered analysis of variance.},
  author    = {Ruth Marcus and Eric Peritz and K. R. Gabriel},
  journal   = {Biometrika},
  number    = {3},
  pages     = {655--660},
  publisher = {[Oxford University Press, Biometrika Trust]},
  title     = {On Closed Testing Procedures with Special Reference to Ordered Analysis of Variance},
  urldate   = {2022-12-09},
  volume    = {63},
  year      = {1976}
}

@article{imbens2004confidence,
  title     = {Confidence intervals for partially identified parameters},
  author    = {Imbens, Guido W and Manski, Charles F},
  journal   = {Econometrica},
  volume    = {72},
  number    = {6},
  pages     = {1845--1857},
  year      = {2004},
  publisher = {Wiley Online Library}
}

@article{chernozhukov2007estimation,
  issn      = {00129682, 14680262},
  url       = {http://www.jstor.org/stable/4502031},
  abstract  = {This paper develops a framework for performing estimation and inference in econo- metric models with partial identification, focusing particularly on models character- ized by moment inequalities and equalities. Applications of this framework include the analysis of game-theoretic models, revealed preference restrictions, regressions with missing and corrupted data, auction models, structural quantile regressions, and asset pricing models. Specifically, we provide estimators and confidence regions for the set of minimizers $\Theta_I$ of an econometric criterion function $Q(\Theta)$. In applications, the criterion function embodies testable restrictions on economic models. A parameter value Θ that describes an economic model satisfies these restrictions if $Q(\Theta)$ attains its minimum at this value. Interest therefore focuses on the set of minimizers, called the identified set. We use the inversion of the sample analog, $Q_n(\Theta)$, of the population criterion, $Q(\Theta)$, to construct estimators and confidence regions for the identified set, and develop consistency, rates of convergence, and inference results for these estimators and regions. To derive these results, we develop methods for analyzing the asymptotic properties of sample criterion functions under set identification.},
  author    = {Victor Chernozhukov and Han Hong and Elie Tamer},
  journal   = {Econometrica},
  number    = {5},
  pages     = {1243--1284},
  publisher = {[Wiley, The Econometric Society]},
  title     = {Estimation and Confidence Regions for Parameter Sets in Econometric Models},
  urldate   = {2022-12-09},
  volume    = {75},
  year      = {2007}
}

@inproceedings{namkoong2020offpolicy,
  author    = {Namkoong, Hongseok and Keramati, Ramtin and Yadlowsky, Steve and Brunskill, Emma},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {18819--18831},
  publisher = {Curran Associates, Inc.},
  title     = {Off-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding},
  url       = {https://proceedings.neurips.cc/paper/2020/file/da21bae82c02d1e2b8168d57cd3fbab7-Paper.pdf},
  volume    = {33},
  year      = {2020}
}

@book{rosenbaum2002observational,
  title     = {Observational Studies},
  author    = {Rosenbaum, Paul R.},
  year      = {2002},
  publisher = {Springer},
  address   = {New York, NY}
}

@inproceedings{kallus2018confounding,
  author    = {Kallus, Nathan and Zhou, Angela},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Confounding-Robust Policy Improvement},
  url       = {https://proceedings.neurips.cc/paper/2018/file/3a09a524440d44d7f19870070a5ad42f-Paper.pdf},
  volume    = {31},
  year      = {2018}
}

@article{tan2006distributional,
  title     = {A distributional approach for causal inference using propensity scores},
  author    = {Tan, Zhiqiang},
  journal   = {Journal of the American Statistical Association},
  volume    = {101},
  number    = {476},
  pages     = {1619--1637},
  year      = {2006},
  publisher = {Taylor \& Francis}
}

@inproceedings{hussain2022falsification,
  author     = {Hussain, Zeshan and Oberst, Michael and Shih, Ming-Chieh and
                Sontag, David},
  booktitle  = {Advances in Neural Information Processing Systems},
  conference = {NeurIPS},
  month      = {September},
  title      = {Falsification before Extrapolation in Causal Effect Estimation},
  year       = {2022}
}

@article{cox1975note,
  title     = {A note on data-splitting for the evaluation of significance levels},
  author    = {Cox, David R},
  journal   = {Biometrika},
  volume    = {62},
  number    = {2},
  pages     = {441--444},
  year      = {1975},
  publisher = {Oxford University Press}
}

@article{yadlowsky2022bounds,
  author    = {Steve Yadlowsky and Hongseok Namkoong and Sanjay Basu and John Duchi and Lu Tian},
  title     = {{Bounds on the conditional and average treatment effect with unobserved confounding factors}},
  volume    = {50},
  journal   = {The Annals of Statistics},
  number    = {5},
  publisher = {Institute of Mathematical Statistics},
  pages     = {2587 -- 2615},
  keywords  = {Causal estimation, omitted variable, semiparametric inference, sensitivity analysis},
  year      = {2022},
  doi       = {10.1214/22-AOS2195},
  url       = {https://doi.org/10.1214/22-AOS2195}
}

@book{manski1995identification,
  title     = {{Identification Problems in the Social Sciences}},
  author    = {Manski, Charles F},
  year      = {1995},
  publisher = {Harvard University Press}
}

@article{allamaa2022sim2real,
  title    = {Sim2real for Autonomous Vehicle Control using Executable Digital Twin},
  journal  = {IFAC-PapersOnLine},
  volume   = {55},
  number   = {24},
  pages    = {385-391},
  year     = {2022},
  note     = {10th IFAC Symposium on Advances in Automotive Control AAC 2022},
  issn     = {2405-8963},
  doi      = {https://doi.org/10.1016/j.ifacol.2022.10.314},
  url      = {https://www.sciencedirect.com/science/article/pii/S2405896322023461},
  author   = {Jean Pierre Allamaa and Panagiotis Patrinos and Herman {Van der Auweraer} and Tong Duy Son},
  keywords = {Sim2Real, ADAS, model predictive control, domain randomization},
  abstract = {In this work, we propose a sim2real method to transfer and adapt a nonlinear model predictive controller (NMPC) from simulation to the real target system based on executable digital twin (xDT). The xDT model is a high fidelity vehicle dynamics simulator, executable online in the control parameter randomization and learning process. The parameters are adapted to gradually improve control performance and deal with changing real-world environment. In particular, the performance metric is not required to be differentiable nor analytical with respect to the control parameters and system dynamics are not necessary linearized. Eventually, the proposed sim2real framework leverages altogether online high fidelity simulator, data-driven estimations, and simulation based optimization to transfer and adapt efficiently a controller developed in simulation environment to the real platform. Our experiment demonstrates that a high control performance is achieved without tedious time and labor consuming tuning.}
}

@article{greenwade93,
  author  = {George D. Greenwade},
  title   = {The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})},
  year    = {1993},
  journal = {TUGBoat},
  volume  = {14},
  number  = {3},
  pages   = {342--351}
}
@inproceedings{thomas2016data,
  author    = {Thomas, Philip S. and Brunskill, Emma},
  title     = {Data-Efficient off-Policy Policy Evaluation for Reinforcement Learning},
  year      = {2016},
  publisher = {JMLR.org},
  abstract  = {In this paper we present a new way of predicting the performance of a reinforcement learning policy given historical data that may have been generated by a different policy. The ability to evaluate a policy from historical data is important for applications where the deployment of a bad policy can be dangerous or costly. We show empirically that our algorithm produces estimates that often have orders of magnitude lower mean squared error than existing methods--it makes more efficient use of the available data. Our new estimator is based on two advances: an extension of the doubly robust estimator (Jiang &amp; Li, 2015), and a new way to mix between model based and importance sampling based estimates.},
  booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
  pages     = {2139–2148},
  numpages  = {10},
  location  = {New York, NY, USA},
  series    = {ICML'16}
}
@inproceedings{saito2022off,
  title        = {Off-Policy Evaluation for Large Action Spaces via Embeddings},
  author       = {Saito, Yuta and Joachims, Thorsten},
  booktitle    = {Proceedings of the 39th International Conference on Machine Learning},
  pages        = {19089--19122},
  year         = {2022},
  organization = {PMLR}
}
@inproceedings{saito2021evaluating,
  author    = {Saito, Yuta and Udagawa, Takuma and Kiyohara, Haruka and Mogi, Kazuki and Narita, Yusuke and Tateno, Kei},
  title     = {Evaluating the Robustness of Off-Policy Evaluation},
  year      = {2021},
  isbn      = {9781450384582},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3460231.3474245},
  doi       = {10.1145/3460231.3474245},
  abstract  = {Off-policy Evaluation (OPE), or offline evaluation in general, evaluates the performance of hypothetical policies leveraging only offline log data. It is particularly useful in applications where the online interaction involves high stakes and expensive setting such as precision medicine and recommender systems. Since many OPE estimators have been proposed and some of them have hyperparameters to be tuned, there is an emerging challenge for practitioners to select and tune OPE estimators for their specific application. Unfortunately, identifying a reliable estimator from results reported in research papers is often difficult because the current experimental procedure evaluates and compares the estimators’ performance on a narrow set of hyperparameters and evaluation policies. Therefore, it is difficult to know which estimator is safe and reliable to use. In this work, we develop Interpretable Evaluation for Offline Evaluation (IEOE), an experimental procedure to evaluate OPE estimators’ robustness to changes in hyperparameters and/or evaluation policies in an interpretable manner. Then, using the IEOE procedure, we perform extensive evaluation of a wide variety of existing estimators on Open Bandit Dataset, a large-scale public real-world dataset for OPE. We demonstrate that our procedure can evaluate the estimators’ robustness to the hyperparamter choice, helping us avoid using unsafe estimators. Finally, we apply IEOE to real-world e-commerce platform data and demonstrate how to use our protocol in practice.},
  booktitle = {Proceedings of the 15th ACM Conference on Recommender Systems},
  pages     = {114–123},
  numpages  = {10},
  keywords  = {recommender systems, counterfactual estimation, off-policy evaluation},
  location  = {Amsterdam, Netherlands},
  series    = {RecSys '21}
}
@inproceedings{wang2017optimal,
  author    = {Wang, Yu-Xiang and Agarwal, Alekh and Dud\'{\i}k, Miroslav},
  title     = {Optimal and Adaptive Off-Policy Evaluation in Contextual Bandits},
  year      = {2017},
  publisher = {JMLR.org},
  abstract  = {We study the off-policy evaluation problem— estimating the value of a target policy using data collected by another policy—under the contextual bandit model. We consider the general (agnostic) setting without access to a consistent model of rewards and establish a minimax lower bound on the mean squared error (MSE). The bound is matched up to constants by the inverse propensity scoring (IPS) and doubly robust (DR) estimators. This highlights the difficulty of the agnostic contextual setting, in contrast with multi-armed bandits and contextual bandits with access to a consistent reward model, where IPS is suboptimal. We then propose the SWITCH estimator, which can use an existing reward model (not necessarily consistent) to achieve a better bias-variance tradeoff than IPS and DR. We prove an upper bound on its MSE and demonstrate its benefits empirically on a diverse collection of data sets, often outperforming prior work by orders of magnitude.},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
  pages     = {3589–3597},
  numpages  = {9},
  location  = {Sydney, NSW, Australia},
  series    = {ICML'17}
}

@article{kallus2020off,
  author     = {Kallus, Nathan and Uehara, Masatoshi},
  title      = {Double Reinforcement Learning for Efficient Off-Policy Evaluation in Markov Decision Processes},
  year       = {2022},
  issue_date = {January 2020},
  publisher  = {JMLR.org},
  volume     = {21},
  number     = {1},
  issn       = {1532-4435},
  abstract   = {Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate novel decision policies without needing to conduct exploration, which is often costly or otherwise infeasible. We consider for the first time the semiparametric efficiency limits of OPE in Markov decision processes (MDPs), where actions, rewards, and states are memoryless. We show existing OPE estimators may fail to be efficient in this setting. We develop a new estimator based on cross-fold estimation of q-functions and marginalized density ratios, which we term double reinforcement learning (DRL). We show that DRL is efficient when both components are estimated at fourth-root rates and is also doubly robust when only one component is consistent. We investigate these properties empirically and demonstrate the performance benefits due to harnessing memorylessness.},
  journal    = {J. Mach. Learn. Res.},
  month      = {jun},
  articleno  = {167},
  numpages   = {63},
  keywords   = {semiparametric efficiency, Markov decision processes, double machine learning, off-policy evaluation}
}

@inproceedings{liu2018breaking,
  author    = {Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation},
  url       = {https://proceedings.neurips.cc/paper/2018/file/dda04f9d634145a9c68d5dfe53b21272-Paper.pdf},
  volume    = {31},
  year      = {2018}
}



@inproceedings{Fujimoto2021deep,
  title     = {A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation},
  author    = {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages     = {3518--3529},
  year      = {2021},
  editor    = {Meila, Marina and Zhang, Tong},
  volume    = {139},
  series    = {Proceedings of Machine Learning Research},
  month     = {18--24 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v139/fujimoto21a/fujimoto21a.pdf},
  url       = {https://proceedings.mlr.press/v139/fujimoto21a.html},
  abstract  = {Marginalized importance sampling (MIS), which measures the density ratio between the state-action occupancy of a target policy and that of a sampling distribution, is a promising approach for off-policy evaluation. However, current state-of-the-art MIS methods rely on complex optimization tricks and succeed mostly on simple toy problems. We bridge the gap between MIS and deep reinforcement learning by observing that the density ratio can be computed from the successor representation of the target policy. The successor representation can be trained through deep reinforcement learning methodology and decouples the reward optimization from the dynamics of the environment, making the resulting algorithm stable and applicable to high-dimensional domains. We evaluate the empirical performance of our approach on a variety of challenging Atari and MuJoCo environments.}
}
@inproceedings{xie2019advances,
  author    = {Xie, Tengyang and Ma, Yifei and Wang, Yu-Xiang},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling},
  url       = {https://proceedings.neurips.cc/paper/2019/file/4ffb0d2ba92f664c2281970110a2e071-Paper.pdf},
  volume    = {32},
  year      = {2019}
}

@misc{liu2019triply,
  doi       = {10.48550/ARXIV.1911.05811},
  url       = {https://arxiv.org/abs/1911.05811},
  author    = {Liu, Anqi and Liu, Hao and Anandkumar, Anima and Yue, Yisong},
  keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Triply Robust Off-Policy Evaluation},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{liu2020understanding,
  author    = {Liu, Yao and Bacon, Pierre-Luc and Brunskill, Emma},
  title     = {Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling},
  year      = {2020},
  publisher = {JMLR.org},
  abstract  = {Off-policy policy estimators that use importance sampling (IS) can suffer from high variance in long-horizon domains, and there has been particular excitement over new IS methods that leverage the structure of Markov decision processes. We analyze the variance of the most popular approaches through the viewpoint of conditional Monte Carlo. Surprisingly, we find that in finite horizon MDPs there is no strict variance reduction of per-decision importance sampling or marginalized importance sampling, comparing with vanilla importance sampling. We then provide sufficient conditions under which the perdecision or marginalized estimators will provably reduce the variance over importance sampling with finite horizons. For the asymptotic (in terms of horizon T) case, we develop upper and lower bounds on the variance of those estimators which yields sufficient conditions under which there exists an exponential v.s. polynomial gap between the variance of importance sampling and that of the per-decision or stationary/marginalized estimators. These results help advance our understanding of if and when new types of IS estimators will improve the accuracy of off-policy estimation.},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  articleno = {574},
  numpages  = {10},
  series    = {ICML'20}
}

@article{dudik2014doubly,
  issn      = {08834237, 21688745},
  url       = {http://www.jstor.org/stable/43288496},
  abstract  = {We study sequential decision making in environments where rewards are only partially observed, but can be modeled as a function of observed contexts and the chosen action by the decision maker. This setting, known as contextual bandits, encompasses a wide variety of applications such as health care, content recommendation and Internet advertising. A central task is evaluation of a new policy given historic data consisting of contexts, actions and received rewards. The key challenge is that the past data typically does not faithfully represent proportions of actions taken by a new policy. Previous approaches rely either on models of rewards or models of the past policy. The former are plagued by a large bias whereas the latter have a large variance. In this work, we leverage the strengths and overcome the weaknesses of the two approaches by applying the doubly robust estimation technique to the problems of policy evaluation and optimization. We prove that this approach yields accurate value estimates when we have either a good (but not necessarily consistent) model of rewards or a good (but not necessarily consistent) model of past policy. Extensive empirical comparison demonstrates that the doubly robust estimation uniformly improves over existing techniques, achieving both lower variance in value estimation and better policies. As such, we expect the doubly robust approach to become common practice in policy evaluation and optimization.},
  author    = {Miroslav Dudík and Dumitru Erhan and John Langford and Lihong Li},
  journal   = {Statistical Science},
  number    = {4},
  pages     = {485--511},
  publisher = {Institute of Mathematical Statistics},
  title     = {Doubly Robust Policy Evaluation and Optimization},
  urldate   = {2022-12-21},
  volume    = {29},
  year      = {2014}
}

@article{horvitz1952generalization,
  issn      = {01621459},
  url       = {http://www.jstor.org/stable/2280784},
  abstract  = {This paper presents a general technique for the treatment of samples drawn without replacement from finite universes when unequal selection probabilities are used. Two sampling schemes are discussed in connection with the problem of determining optimum selection probabilities according to the information available in a supplementary variable. Admittedly, these two schemes have limited application. They should prove useful, however, for the first stage of sampling with multi-stage designs, since both permit unbiased estimation of the sampling variance without resorting to additional assumptions.},
  author    = {D. G. Horvitz and D. J. Thompson},
  journal   = {Journal of the American Statistical Association},
  number    = {260},
  pages     = {663--685},
  publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
  title     = {A Generalization of Sampling Without Replacement From a Finite Universe},
  urldate   = {2022-12-21},
  volume    = {47},
  year      = {1952}
}

@article{saito2020open,
  title   = {Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation},
  author  = {Saito, Yuta and Shunsuke, Aihara and Megumi, Matsutani and Yusuke, Narita},
  journal = {arXiv preprint arXiv:2008.07146},
  year    = {2020}
}

@inproceedings{su2020doubly,
  author    = {Su, Yi and Dimakopoulou, Maria and Krishnamurthy, Akshay and Dud\'{\i}k, Miroslav},
  title     = {Doubly Robust Off-Policy Evaluation with Shrinkage},
  year      = {2020},
  publisher = {JMLR.org},
  abstract  = {We propose a new framework for designing estimators for off-policy evaluation in contextual bandits. Our approach is based on the asymptotically optimal doubly robust estimator, but we shrink the importance weights to minimize a bound on the mean squared error, which results in a better bias-variance tradeoff in finite samples. We use this optimization-based framework to obtain three estimators: (a) a weight-clipping estimator, (b) a new weight-shrinkage estimator, and (c) the first shrinkage-based estimator for combinatorial action sets. Extensive experiments in both standard and combinatorial bandit benchmark problems show that our estimators are highly adaptive and typically outperform state-of-the-art methods.},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  articleno = {850},
  numpages  = {10},
  series    = {ICML'20}
}

@misc{dua2019uci,
  author      = {Dua, Dheeru and Graff, Casey},
  year        = {2017},
  title       = {{UCI} Machine Learning Repository},
  url         = {http://archive.ics.uci.edu/ml},
  institution = {University of California, Irvine, School of Information and Computer Sciences}
}

@article{deng2012mnist,
  title     = {The mnist database of handwritten digit images for machine learning research},
  author    = {Deng, Li},
  journal   = {IEEE Signal Processing Magazine},
  volume    = {29},
  number    = {6},
  pages     = {141--142},
  year      = {2012},
  publisher = {IEEE}
}

@inproceedings{kallus2021optimal,
  title        = {Optimal off-policy evaluation from multiple logging policies},
  author       = {Kallus, Nathan and Saito, Yuta and Uehara, Masatoshi},
  booktitle    = {International Conference on Machine Learning},
  pages        = {5247--5256},
  year         = {2021},
  organization = {PMLR}
}

@misc{tchetgen2020introduction,
  title         = {An Introduction to Proximal Causal Learning},
  author        = {Eric J Tchetgen Tchetgen and Andrew Ying and Yifan Cui and Xu Shi and Wang Miao},
  year          = {2020},
  eprint        = {2009.10982},
  archiveprefix = {arXiv},
  primaryclass  = {id='stat.ME' full_name='Methodology' is_active=True alt_name=None in_archive='stat' is_general=False description='Design, Surveys, Model Selection, Multiple Testing, Multivariate Methods, Signal and Image Processing, Time Series, Smoothing, Spatial Statistics, Survival Analysis, Nonparametric and Semiparametric Methods'}
}

@inproceedings{xu2021deep,
  title     = {Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation},
  author    = {Liyuan Xu and Heishiro Kanagawa and Arthur Gretton},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
  year      = {2021},
  url       = {https://openreview.net/forum?id=0FDxsIEv9G}
}

@article{kallus2020minimax,
  author  = {Kallus, Nathan and Zhou, Angela},
  year    = {2020},
  month   = {10},
  pages   = {},
  title   = {Minimax-Optimal Policy Learning Under Unobserved Confounding},
  volume  = {67},
  journal = {Management Science},
  doi     = {10.1287/mnsc.2020.3699}
}

@inproceedings{mehrdad2018more,
  title  = {More Robust Doubly Robust Off-policy Evaluation},
  author = {Mehrdad Farajtabar and Mohammad Ghavamzadeh and Yinlam Chow},
  year   = {2018}
}

@inproceedings{rowland2020conditional,
  title        = {Conditional importance sampling for off-policy learning},
  author       = {Rowland, Mark and Harutyunyan, Anna and Hasselt, Hado and Borsa, Diana and Schaul, Tom and Munos, R{\'e}mi and Dabney, Will},
  booktitle    = {International Conference on Artificial Intelligence and Statistics},
  pages        = {45--55},
  year         = {2020},
  organization = {PMLR}
}

@misc{lai2023generalization,
  doi       = {10.48550/ARXIV.2302.05933},
  url       = {https://arxiv.org/abs/2302.05933},
  author    = {Lai, Jianfa and Xu, Manyun and Chen, Rui and Lin, Qian},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences, G.3, 62G08 (Primary), 68T07 (secondary), 46E22},
  title     = {Generalization Ability of Wide Neural Networks on $\mathbb{R}$},
  publisher = {arXiv},
  year      = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{breiman2001machine,
  abstract      = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  author        = {Breiman, Leo},
  da            = {2001/10/01},
  date-added    = {2023-03-02 18:03:17 +0000},
  date-modified = {2023-03-02 18:03:17 +0000},
  doi           = {10.1023/A:1010933404324},
  id            = {Breiman2001},
  isbn          = {1573-0565},
  journal       = {Machine Learning},
  number        = {1},
  pages         = {5--32},
  title         = {Random Forests},
  ty            = {JOUR},
  url           = {https://doi.org/10.1023/A:1010933404324},
  volume        = {45},
  year          = {2001},
  bdsk-url-1    = {https://doi.org/10.1023/A:1010933404324}
}


@misc{newey2018cross,
  doi       = {10.48550/ARXIV.1801.09138},
  url       = {https://arxiv.org/abs/1801.09138},
  author    = {Newey, Whitney K. and Robins, James R.},
  keywords  = {Statistics Theory (math.ST), FOS: Mathematics, FOS: Mathematics},
  title     = {Cross-Fitting and Fast Remainder Rates for Semiparametric Estimation},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{louizos2017causal,
  author    = {Louizos, Christos and Shalit, Uri and Mooij, Joris and Sontag, David and Zemel, Richard and Welling, Max},
  title     = {Causal Effect Inference with Deep Latent-Variable Models},
  year      = {2017},
  isbn      = {9781510860964},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {Learning individual-level causal effects from observational data, such as inferring the most effective medication for a specific patient, is a problem of growing importance for policy makers. The most important aspect of inferring causal effects from observational data is the handling of confounders, factors that affect both an intervention and its outcome. A carefully designed observational study attempts to measure all important confounders. However, even if one does not have direct access to all confounders, there may exist noisy and uncertain measurement of proxies for confounders. We build on recent advances in latent variable modeling to simultaneously estimate the unknown latent space summarizing the confounders and the causal effect. Our method is based on Variational Autoencoders (VAE) which follow the causal structure of inference with proxies. We show our method is significantly more robust than existing methods, and matches the state-of-the-art on previous benchmarks focused on individual treatment effects.},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages     = {6449–6459},
  numpages  = {11},
  location  = {Long Beach, California, USA},
  series    = {NIPS'17}
}

@article{lin2020optimal,
  title    = {Optimal rates for spectral algorithms with least-squares regression over Hilbert spaces},
  journal  = {Applied and Computational Harmonic Analysis},
  volume   = {48},
  number   = {3},
  pages    = {868-890},
  year     = {2020},
  issn     = {1063-5203},
  doi      = {https://doi.org/10.1016/j.acha.2018.09.009},
  url      = {https://www.sciencedirect.com/science/article/pii/S1063520318300174},
  author   = {Junhong Lin and Alessandro Rudi and Lorenzo Rosasco and Volkan Cevher},
  keywords = {Learning theory, Reproducing kernel Hilbert space, Sampling operator, Regularization scheme, Regression},
  abstract = {In this paper, we study regression problems over a separable Hilbert space with the square loss, covering non-parametric regression over a reproducing kernel Hilbert space. We investigate a class of spectral/regularized algorithms, including ridge regression, principal component regression, and gradient methods. We prove optimal, high-probability convergence results in terms of variants of norms for the studied algorithms, considering a capacity assumption on the hypothesis space and a general source condition on the target function. Consequently, we obtain almost sure convergence results with optimal rates. Our results improve and generalize previous results, filling a theoretical gap for the non-attainable cases.}
}

@inproceedings{farajtabar2018more,
  title     = {More Robust Doubly Robust Off-policy Evaluation},
  author    = {Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  pages     = {1447--1456},
  year      = {2018},
  editor    = {Dy, Jennifer and Krause, Andreas},
  volume    = {80},
  series    = {Proceedings of Machine Learning Research},
  month     = {10--15 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v80/farajtabar18a/farajtabar18a.pdf},
  url       = {https://proceedings.mlr.press/v80/farajtabar18a.html},
  abstract  = {We study the problem of off-policy evaluation (OPE) in reinforcement learning (RL), where the goal is to estimate the performance of a policy from the data generated by another policy(ies). In particular, we focus on the doubly robust (DR) estimators that consist of an importance sampling (IS) component and a performance model, and utilize the low (or zero) bias of IS and low variance of the model at the same time. Although the accuracy of the model has a huge impact on the overall performance of DR, most of the work on using the DR estimators in OPE has been focused on improving the IS part, and not much on how to learn the model. In this paper, we propose alternative DR estimators, called more robust doubly robust (MRDR), that learn the model parameter by minimizing the variance of the DR estimator. We first present a formulation for learning the DR model in RL. We then derive formulas for the variance of the DR estimator in both contextual bandits and RL, such that their gradients w.r.t. the model parameters can be estimated from the samples, and propose methods to efficiently minimize the variance. We prove that the MRDR estimators are strongly consistent and asymptotically optimal. Finally, we evaluate MRDR in bandits and RL benchmark problems, and compare its performance with the existing methods.}
}



@inproceedings{su2019continuous,
  title     = {{CAB}: Continuous Adaptive Blending for Policy Evaluation and Learning},
  author    = {Su, Yi and Wang, Lequn and Santacatterina, Michele and Joachims, Thorsten},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {6005--6014},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/su19a/su19a.pdf},
  url       = {https://proceedings.mlr.press/v97/su19a.html},
  abstract  = {The ability to perform offline A/B-testing and off-policy learning using logged contextual bandit feedback is highly desirable in a broad range of applications, including recommender systems, search engines, ad placement, and personalized health care. Both offline A/B-testing and off-policy learning require a counterfactual estimator that evaluates how some new policy would have performed, if it had been used instead of the logging policy. In this paper, we identify a family of counterfactual estimators which subsumes most such estimators proposed to date. Our analysis of this family identifies a new estimator - called Continuous Adaptive Blending (CAB) - which enjoys many advantageous theoretical and practical properties. In particular, it can be substantially less biased than clipped Inverse Propensity Score (IPS) weighting and the Direct Method, and it can have less variance than Doubly Robust and IPS estimators. In addition, it is sub-differentiable such that it can be used for learning, unlike the SWITCH estimator. Experimental results show that CAB provides excellent evaluation accuracy and outperforms other counterfactual estimators in terms of learning performance.}
}

@inproceedings{metelli2021subgaussian,
  author    = {Metelli, Alberto Maria and Russo, Alessio and Restelli, Marcello},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages     = {8119--8132},
  publisher = {Curran Associates, Inc.},
  title     = {Subgaussian and Differentiable Importance Sampling for Off-Policy Evaluation and Learning},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2021/file/4476b929e30dd0c4e8bdbcc82c6ba23a-Paper.pdf},
  volume    = {34},
  year      = {2021}
}

@inproceedings{voloshin2021empirical,
  title     = {Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning},
  author    = {Cameron Voloshin and Hoang Minh Le and Nan Jiang and Yisong Yue},
  booktitle = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
  year      = {2021},
  url       = {https://openreview.net/forum?id=IsK8iKbL-I}
}

@inproceedings{sachdeva2020off,
  author    = {Sachdeva, Noveen and Su, Yi and Joachims, Thorsten},
  title     = {Off-Policy Bandits with Deficient Support},
  year      = {2020},
  isbn      = {9781450379984},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3394486.3403139},
  doi       = {10.1145/3394486.3403139},
  abstract  = {Learning effective contextual-bandit policies from past actions of a deployed system is highly desirable in many settings (e.g. voice assistants, recommendation, search), since it enables the reuse of large amounts of log data. State-of-the-art methods for such off-policy learning, however, are based on inverse propensity score (IPS) weighting. A key theoretical requirement of IPS weighting is that the policy that logged the data has "full support", which typically translates into requiring non-zero probability for any action in any context. Unfortunately, many real-world systems produce support deficient data, especially when the action space is large, and we show how existing methods can fail catastrophically. To overcome this gap between theory and applications, we identify three approaches that provide various guarantees for IPS-based learning despite the inherent limitations of support-deficient data: restricting the action space, reward extrapolation, and restricting the policy space. We systematically analyze the statistical and computational properties of these three approaches, and we empirically evaluate their effectiveness. In addition to providing the first systematic analysis of support-deficiency in contextual-bandit learning, we conclude with recommendations that provide practical guidance.},
  booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages     = {965–975},
  numpages  = {11},
  keywords  = {implicit feed-back, log data, off-policy learning, counterfactual reasoning, contextual bandits},
  location  = {Virtual Event, CA, USA},
  series    = {KDD '20}
}

@inproceedings{swaminathan2015counterfactual,
  author    = {Swaminathan, Adith and Joachims, Thorsten},
  title     = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
  year      = {2015},
  publisher = {JMLR.org},
  abstract  = {We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. These constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method - called Policy Optimizer for Exponential Models (POEM) - for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. POEM is evaluated on several multi-label classification problems showing substantially improved robustness and generalization performance compared to the state-of-the-art.},
  booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
  pages     = {814–823},
  numpages  = {10},
  location  = {Lille, France},
  series    = {ICML'15}
}

@inproceedings{swaminathan2015the,
  author    = {Swaminathan, Adith and Joachims, Thorsten},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {The Self-Normalized Estimator for Counterfactual Learning},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2015/file/39027dfad5138c9ca0c474d71db915c3-Paper.pdf},
  volume    = {28},
  year      = {2015}
}

@inproceedings{li2010contextual,
  author    = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E.},
  title     = {A Contextual-Bandit Approach to Personalized News Article Recommendation},
  year      = {2010},
  isbn      = {9781605587998},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1772690.1772758},
  doi       = {10.1145/1772690.1772758},
  abstract  = {Personalized web services strive to adapt their services (advertisements, news articles, etc.) to individual users by making use of both content and user information. Despite a few recent advances, this problem remains challenging for at least two reasons. First, web service is featured with dynamically changing pools of content, rendering traditional collaborative filtering methods inapplicable. Second, the scale of most web services of practical interest calls for solutions that are both fast in learning and computation.In this work, we model personalized recommendation of news articles as a contextual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles, while simultaneously adapting its article-selection strategy based on user-click feedback to maximize total user clicks.The contributions of this work are three-fold. First, we propose a new, general contextual bandit algorithm that is computationally efficient and well motivated from learning theory. Second, we argue that any bandit algorithm can be reliably evaluated offline using previously recorded random traffic. Finally, using this offline evaluation method, we successfully applied our new algorithm to a Yahoo! Front Page Today Module dataset containing over 33 million events. Results showed a 12.5\% click lift compared to a standard context-free bandit algorithm, and the advantage becomes even greater when data gets more scarce.},
  booktitle = {Proceedings of the 19th International Conference on World Wide Web},
  pages     = {661–670},
  numpages  = {10},
  keywords  = {exploration/exploitation dilemma, contextual bandit, recommender systems, personalization, web service},
  location  = {Raleigh, North Carolina, USA},
  series    = {WWW '10}
}

@article{bastani2019online,
  author  = {Bastani, Hamsa and Bayati, Mohsen},
  year    = {2019},
  month   = {11},
  pages   = {},
  title   = {Online Decision Making with High-Dimensional Covariates},
  volume  = {68},
  journal = {Operations Research},
  doi     = {10.1287/opre.2019.1902}
}

@article{xu2020contextual,
  author  = {Xu, Xiao and Dong, Fang and Li, Yanghua and He, Shaojian and Li, Xin},
  year    = {2020},
  month   = {04},
  pages   = {6518-6525},
  title   = {Contextual-Bandit Based Personalized Recommendation with Time-Varying User Interests},
  volume  = {34},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi     = {10.1609/aaai.v34i04.6125}
}

@book{sugiyama2012machine,
  isbn      = {9780262017091},
  url       = {http://www.jstor.org/stable/j.ctt5hhbtm},
  abstract  = {As the power of computing has grown over the past few decades, the field of machine learning has advanced rapidly in both theory and practice. Machine learning methods are usually based on the assumption that the data generation mechanism does not change over time. Yet real-world applications of machine learning, including image recognition, natural language processing, speech recognition, robot control, and bioinformatics, often violate this common assumption. Dealing with non-stationarity is one of modern machine learning's greatest challenges. This book focuses on a specific non-stationary environment known as covariate shift, in which the distributions of inputs (queries) change but the conditional distribution of outputs (answers) is unchanged, and presents machine learning theory, algorithms, and applications to overcome this variety of non-stationarity. After reviewing the state-of-the-art research in the field, the authors discuss topics that include learning under covariate shift, model selection, importance estimation, and active learning. They describe such real world applications of covariate shift adaption as brain-computer interface, speaker identification, and age prediction from facial images. With this book, they aim to encourage future research in machine learning, statistics, and engineering that strives to create truly autonomous learning machines able to learn under non-stationarity.},
  author    = {Masashi Sugiyama and Motoaki Kawanabe},
  publisher = {The MIT Press},
  title     = {Machine Learning in Non-Stationary Environments: Introduction to Covariate Shift Adaptation},
  urldate   = {2023-04-13},
  year      = {2012}
}

@inproceedings{swaminathan2017off,
  author    = {Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dud\'{\i}k, Miroslav and Langford, John and Jose, Damien and Zitouni, Imed},
  title     = {Off-Policy Evaluation for Slate Recommendation},
  year      = {2017},
  isbn      = {9781510860964},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {This paper studies the evaluation of policies that recommend an ordered set of items (e.g., a ranking) based on some context—a common scenario in web search, ads, and recommendation. We build on techniques from combinatorial bandits to introduce a new practical estimator that uses logged data to estimate a policy's performance. A thorough empirical evaluation on real-world data reveals that our estimator is accurate in a variety of settings, including as a subroutine in a learning-to-rank task, where it achieves competitive performance. We derive conditions under which our estimator is unbiased—these conditions are weaker than prior heuristics for slate evaluation—and experimentally demonstrate a smaller bias than parametric approaches, even when these conditions are violated. Finally, our theory and experiments also show exponential savings in the amount of required data compared with general unbiased estimators.},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages     = {3635–3645},
  numpages  = {11},
  location  = {Long Beach, California, USA},
  series    = {NIPS'17}
}

@article{robins1986new,
  title    = {A new approach to causal inference in mortality studies with a sustained exposure period—application to control of the healthy worker survivor effect},
  journal  = {Mathematical Modelling},
  volume   = {7},
  number   = {9},
  pages    = {1393-1512},
  year     = {1986},
  issn     = {0270-0255},
  doi      = {https://doi.org/10.1016/0270-0255(86)90088-6},
  url      = {https://www.sciencedirect.com/science/article/pii/0270025586900886},
  author   = {James Robins},
  abstract = {In observational cohort mortality studies with prolonged periods of exposure to the agent under study, it is not uncommon for risk factors for death to be determinants of subsequent exposure. For instance, in occupational mortality studies date of termination of employment is both a determinant of future exposure (since terminated individuals receive no further exposure) and an independent risk factor for death (since disabled individuals tend to leave employment). When current risk factor status determines subsequent exposure and is determined by previous exposure, standard analyses that estimate age-specific mortality rates as a function of cumulative exposure may underestimate the true effect of exposure on mortality whether or not one adjusts for the risk factor in the analysis. This observation raises the question, which if any population parameters can be given a causal interpretation in observational mortality studies? In answer, we offer a graphical approach to the identification and computation of causal parameters in mortality studies with sustained exposure periods. This approach is shown to be equivalent to an approach in which the observational study is identified with a hypothetical double-blind randomized trial in which data on each subject's assigned treatment protocol has been erased from the data file. Causal inferences can then be made by comparing mortality as a function of treatment protocol, since, in a double-blind randomized trial missing data on treatment protocol, the association of mortality with treatment protocol can still be estimated. We reanalyze the mortality experience of a cohort of arsenic-exposed copper smelter workers with our method and compare our results with those obtained using standard methods. We find an adverse effect of arsenic exposure on all-cause and lung cancer mortality which standard methods fail to detect.}
}

@misc{schulman2017proximal,
  title         = {Proximal Policy Optimization Algorithms},
  author        = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  year          = {2017},
  eprint        = {1707.06347},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{lambert2022illustrating,
  author  = {Lambert, Nathan and Castricato, Louis and von Werra, Leandro and Havrilla, Alex},
  title   = {Illustrating Reinforcement Learning from Human Feedback (RLHF)},
  journal = {Hugging Face Blog},
  year    = {2022},
  note    = {https://huggingface.co/blog/rlhf}
}

@article{li2018addressing,
  author   = {Li, Fan and Thomas, Laine E and Li, Fan},
  title    = {{Addressing Extreme Propensity Scores via the Overlap Weights}},
  journal  = {American Journal of Epidemiology},
  volume   = {188},
  number   = {1},
  pages    = {250-257},
  year     = {2018},
  month    = {09},
  abstract = {{The popular inverse probability weighting method in causal inference is often hampered by extreme propensity scores, resulting in biased estimates and excessive variance. A common remedy is to trim patients with extreme scores (i.e., remove them from the weighted analysis). However, such methods are often sensitive to the choice of cutoff points and discard a large proportion of the sample. The implications for bias and the precision of the treatment effect estimate are unclear. These problems are mitigated by a newly developed method, the overlap weighting method. Overlap weights emphasize the target population with the most overlap in observed characteristics between treatments, by continuously down-weighting the units in the tails of the propensity score distribution. Here we use simulations to compare overlap weights to standard inverse probability weighting with trimming, in terms of bias, variance, and 95\\% confidence interval coverage. A range of propensity score distributions are considered, including settings with substantial nonoverlap and extreme values. To facilitate practical implementation, we further provide a consistent estimator for the standard error of the treatment effect estimated using overlap weighting.}},
  issn     = {0002-9262},
  doi      = {10.1093/aje/kwy201},
  url      = {https://doi.org/10.1093/aje/kwy201},
  eprint   = {https://academic.oup.com/aje/article-pdf/188/1/250/27238731/kwy201\_li\_web\_material\_final.pdf}
}


@inproceedings{jiang2016doubly,
  title     = {Doubly Robust Off-policy Value Evaluation for Reinforcement Learning},
  author    = {Jiang, Nan and Li, Lihong},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  pages     = {652--661},
  year      = {2016},
  editor    = {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume    = {48},
  series    = {Proceedings of Machine Learning Research},
  address   = {New York, New York, USA},
  month     = {20--22 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v48/jiang16.pdf},
  url       = {https://proceedings.mlr.press/v48/jiang16.html},
  abstract  = {We study the problem of off-policy value evaluation in reinforcement learning (RL), where one aims to estimate the value of a new policy based on data collected by a different policy. This problem is often a critical step when applying RL to real-world problems. Despite its importance, existing general methods either have uncontrolled bias or suffer high variance. In this work, we extend the doubly robust estimator for bandits to sequential decision-making problems, which gets the best of both worlds: it is guaranteed to be unbiased and can have a much lower variance than the popular importance sampling estimators. We demonstrate the estimator’s accuracy in several benchmark problems, and illustrate its use as a subroutine in safe policy improvement. We also provide theoretical results on the inherent hardness of the problem, and show that our estimator can match the lower bound in certain scenarios.}
}

@article{brehmer2020mining,
  title     = {Mining gold from implicit models to improve likelihood-free inference},
  author    = {Brehmer, Johann and Louppe, Gilles and Pavez, Juan and Cranmer, Kyle},
  journal   = {Proceedings of the National Academy of Sciences},
  volume    = {117},
  number    = {10},
  pages     = {5242--5249},
  year      = {2020},
  publisher = {National Acad Sciences}
}

@article{bernton2019schr,
  title   = {Schr\"odinger Bridge Samplers},
  author  = {Bernton, Espen and Heng, Jeremy and Doucet, Arnaud and Jacob, Pierre E},
  journal = {arXiv preprint arXiv:1912.13170},
  year    = {2019}
}


@article{meng1996simulating,
  title     = {Simulating ratios of normalizing constants via a simple identity: a theoretical exploration},
  author    = {Meng, Xiao-Li and Wong, Wing Hung},
  journal   = {Statistica Sinica},
  pages     = {831--860},
  year      = {1996},
  publisher = {JSTOR}
}

@book{pearl2009causality,
  place     = {Cambridge},
  edition   = {2},
  title     = {Causality},
  doi       = {10.1017/CBO9780511803161},
  publisher = {Cambridge University Press},
  author    = {Pearl, Judea},
  year      = {2009}
}


@inproceedings{sondhi2020balanced,
  title     = {Balanced Off-Policy Evaluation in General Action Spaces},
  author    = {Sondhi, Arjun and Arbour, David and Dimmery, Drew},
  booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages     = {2413--2423},
  year      = {2020},
  editor    = {Chiappa, Silvia and Calandra, Roberto},
  volume    = {108},
  series    = {Proceedings of Machine Learning Research},
  month     = {26--28 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v108/sondhi20a/sondhi20a.pdf},
  url       = {https://proceedings.mlr.press/v108/sondhi20a.html},
  abstract  = {Estimation of importance sampling weights for off-policy evaluation of contextual bandits often results in imbalance—a mismatch between the desired and the actual distribution of state-action pairs after weighting. In this work we present balanced off-policy evaluation (B-OPE), a generic method for estimating weights which minimize this imbalance. Estimation of these weights reduces to a binary classification problem regardless of action type. We show that minimizing the risk of the classifier implies minimization of imbalance to the desired counterfactual distribution. In turn, this is tied to the error of the off-policy estimate, allowing for easy tuning of hyperparameters. We provide experimental evidence that B-OPE improves weighting-based approaches for offline policy evaluation in both discrete and continuous action spaces.}
}

@article{chatterjee2018sample,
  author    = {Sourav Chatterjee and Persi Diaconis},
  title     = {{The sample size required in importance sampling}},
  volume    = {28},
  journal   = {The Annals of Applied Probability},
  number    = {2},
  publisher = {Institute of Mathematical Statistics},
  pages     = {1099 -- 1135},
  keywords  = {Gibbs measure, importance sampling, Monte Carlo methods, phase transition},
  year      = {2018},
  doi       = {10.1214/17-AAP1326},
  url       = {https://doi.org/10.1214/17-AAP1326}
}

@techreport{krizhevsky2009learning,
  title  = {Learning Multiple Layers of Features from Tiny Images},
  author = {Krizhevsky, Alex},
  year   = {2009}
}

@inproceedings{chaudhuri2019london,
  title     = {{B}ayesian Counterfactual Risk Minimization},
  author    = {London, Ben and Sandler, Ted},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {4125--4133},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/london19a/london19a.pdf},
  url       = {https://proceedings.mlr.press/v97/london19a.html},
  abstract  = {We present a Bayesian view of counterfactual risk minimization (CRM) for offline learning from logged bandit feedback. Using PAC-Bayesian analysis, we derive a new generalization bound for the truncated inverse propensity score estimator. We apply the bound to a class of Bayesian policies, which motivates a novel, potentially data-dependent, regularization technique for CRM. Experimental results indicate that this technique outperforms standard $L_2$ regularization, and that it is competitive with variance regularization while being both simpler to implement and more computationally efficient.}
}

@inproceedings{taufiq2023marginal,
  title     = {Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits},
  author    = {Taufiq, Muhammad Faaiz and Doucet, Arnaud and Cornish, Rob and Ton, Jean-Francois},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  year      = {2023},
  url       = {https://openreview.net/forum?id=noyleECBam}
}

@inproceedings{taufiq2022conformal,
  title     = {Conformal Off-Policy Prediction in Contextual Bandits},
  author    = {Muhammad Faaiz Taufiq and Jean-Francois Ton and Rob Cornish and Yee Whye Teh and Arnaud Doucet},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year      = {2022},
  url       = {https://openreview.net/forum?id=IfgOWI5v2f}
}

@misc{cornish2023causalfalsificationdigitaltwins,
  title         = {Causal Falsification of Digital Twins},
  author        = {Rob Cornish and Muhammad Faaiz Taufiq and Arnaud Doucet and Chris Holmes},
  year          = {2023},
  eprint        = {2301.07210},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ME},
  url           = {https://arxiv.org/abs/2301.07210}
}


@inproceedings{taufiq2023manifold,
  title     = {Manifold Restricted Interventional Shapley Values},
  author    = {Taufiq, Muhammad Faaiz and Bl\"obaum, Patrick and Minorics, Lenon},
  booktitle = {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
  pages     = {5079--5106},
  year      = {2023},
  editor    = {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},
  volume    = {206},
  series    = {Proceedings of Machine Learning Research},
  month     = {25--27 Apr},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v206/taufiq23a/taufiq23a.pdf},
  url       = {https://proceedings.mlr.press/v206/taufiq23a.html},
  abstract  = {Shapley values are model-agnostic methods for explaining model predictions. Many commonly used methods of computing Shapley values, known as off-manifold methods, rely on model evaluations on out-of-distribution input samples. Consequently, explanations obtained are sensitive to model behaviour outside the data distribution, which may be irrelevant for all practical purposes. While on-manifold methods have been proposed which do not suffer from this problem, we show that such methods are overly dependent on the input data distribution, and therefore result in unintuitive and misleading explanations. To circumvent these problems, we propose ManifoldShap, which respects the model’s domain of validity by restricting model evaluations to the data manifold. We show, theoretically and empirically, that ManifoldShap is robust to off-manifold perturbations of the model and leads to more accurate and intuitive explanations than existing state-of-the-art Shapley methods.}
}

@misc{taufiq2024achievablefairnessdatautility,
  title         = {Achievable Fairness on Your Data With Utility Guarantees},
  author        = {Muhammad Faaiz Taufiq and Jean-Francois Ton and Yang Liu},
  year          = {2024},
  eprint        = {2402.17106},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML},
  url           = {https://arxiv.org/abs/2402.17106}
}

@misc{liu2024trustworthyllmssurveyguideline,
  title         = {Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment},
  author        = {Yang Liu and Yuanshun Yao and Jean-Francois Ton and Xiaoying Zhang and Ruocheng Guo and Hao Cheng and Yegor Klochkov and Muhammad Faaiz Taufiq and Hang Li},
  year          = {2024},
  eprint        = {2308.05374},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2308.05374}
}

@inproceedings{foffano2023conformal,
  title        = {Conformal off-policy evaluation in markov decision processes},
  author       = {Foffano, Daniele and Russo, Alessio and Proutiere, Alexandre},
  booktitle    = {2023 62nd IEEE Conference on Decision and Control (CDC)},
  pages        = {3087--3094},
  year         = {2023},
  organization = {IEEE}
}

@inproceedings{zhang2023conformal,
  title        = {Conformal off-policy prediction},
  author       = {Zhang, Yingying and Shi, Chengchun and Luo, Shikai},
  booktitle    = {International Conference on Artificial Intelligence and Statistics},
  pages        = {2751--2768},
  year         = {2023},
  organization = {PMLR}
}

@article{kuipers2024conformal,
  title   = {Conformal Off-Policy Prediction for Multi-Agent Systems},
  author  = {Kuipers, Tom and Tumu, Renukanandan and Yang, Shuo and Kazemi, Milad and Mangharam, Rahul and Paoletti, Nicola},
  journal = {arXiv preprint arXiv:2403.16871},
  year    = {2024}
}

@article{SHIMODAIRA2000Improving,
  title    = {Improving predictive inference under covariate shift by weighting the log-likelihood function},
  journal  = {Journal of Statistical Planning and Inference},
  volume   = {90},
  number   = {2},
  pages    = {227-244},
  year     = {2000},
  issn     = {0378-3758},
  doi      = {https://doi.org/10.1016/S0378-3758(00)00115-4},
  url      = {https://www.sciencedirect.com/science/article/pii/S0378375800001154},
  author   = {Hidetoshi Shimodaira},
  keywords = {Akaike information criterion, Design of experiments, Importance sampling, Kullback–Leibler divergence, Misspecification, Sample surveys, Weighted least squares},
  abstract = {A class of predictive densities is derived by weighting the observed samples in maximizing the log-likelihood function. This approach is effective in cases such as sample surveys or design of experiments, where the observed covariate follows a different distribution than that in the whole population. Under misspecification of the parametric model, the optimal choice of the weight function is asymptotically shown to be the ratio of the density function of the covariate in the population to that in the observations. This is the pseudo-maximum likelihood estimation of sample surveys. The optimality is defined by the expected Kullback–Leibler loss, and the optimal weight is obtained by considering the importance sampling identity. Under correct specification of the model, however, the ordinary maximum likelihood estimate (i.e. the uniform weight) is shown to be optimal asymptotically. For moderate sample size, the situation is in between the two extreme cases, and the weight function is selected by minimizing a variant of the information criterion derived as an estimate of the expected loss. The method is also applied to a weighted version of the Bayesian predictive density. Numerical examples as well as Monte-Carlo simulations are shown for polynomial regression. A connection with the robust parametric estimation is discussed.}
}

@article{lu2021rethinking,
  author     = {Nan Lu and
                Tianyi Zhang and
                Tongtong Fang and
                Takeshi Teshima and
                Masashi Sugiyama},
  title      = {Rethinking Importance Weighting for Transfer Learning},
  journal    = {CoRR},
  volume     = {abs/2112.10157},
  year       = {2021},
  url        = {https://arxiv.org/abs/2112.10157},
  eprinttype = {arXiv},
  eprint     = {2112.10157},
  timestamp  = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2112-10157.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}


@article{sugiyama2007covariate,
  title   = {Covariate shift adaptation by importance weighted cross validation},
  author  = {Sugiyama, Masashi and Krauledat, Matthias and M\"uller, Klaus-Robert},
  journal = {Journal of Machine Learning Research},
  volume  = {8},
  number  = {5},
  pages   = {985--1005},
  year    = {2007}
}

@inproceedings{huang2007correcting,
  title     = {Correcting sample selection bias by unlabeled data},
  author    = {Huang, Jiayuan and Gretton, Arthur and Borgwardt, Karsten and Sch{\"o}lkopf, Bernhard and Smola, Alex J},
  booktitle = {Advances in Neural Information Processing Systems 19},
  pages     = {601--608},
  year      = {2007}
}

@inproceedings{sugiyama2008direct,
  title     = {Direct importance estimation with model selection and its application to covariate shift adaptation},
  author    = {Sugiyama, Masashi and Nakajima, Shinichi and Kashima, Hisashi and Buenau, Paul von and Kawanabe, Motoaki},
  booktitle = {Advances in Neural Information Processing Systems 20},
  pages     = {1433--1440},
  year      = {2008}
}




